<!doctype html>
<html lang="en">

<!--
================================================================================
QUADGEN TECHNICAL SPECIFICATION
================================================================================

VERSION: v1.4.1
REVISION DATE: 2025-08-29

================================================================================
SYSTEM OVERVIEW
================================================================================
QuadGEN generates QuadToneRIP .quad files for Epson inkjet printer systems. 
Implementation provides 256-step linearization curves with configurable ink 
limits, linearization data processing, and interpolation algorithms.

SUPPORTED HARDWARE:
- P800: 8-channel configuration (K,C,M,Y,LC,LM,LK,LLK)
- P700-P900: 10-channel configuration (K,C,M,Y,LC,LM,LK,LLK,V,MK)

================================================================================
ARCHITECTURAL IMPLEMENTATION
================================================================================

CURVE PROCESSING PIPELINE:
1. Base curve initialization: Loaded .quad data or linear ramp generation
2. Per-channel linearization: .cube/.txt file application when loaded
3. Global linearization: .cube/.txt file application when loaded
4. Interpolation processing: Sparse data expansion via selected algorithm

INTERPOLATION ALGORITHMS:
- Activation condition: Linearization data loaded with sparse control points
- Disabled condition: Loaded .quad files (256-point complete datasets)
- Available methods: Cubic, Catmull-Rom (tension parameter), PCHIP, Linear
- Control point source: LAB data uses original measurements, .cube uses file samples
- Linear interpolation: Handles non-evenly spaced control points via interval search

DATA POINT SMOOTHING SYSTEM:
- Purpose: Reduce control point count while preserving curve characteristics
- Default method: Ramer-Douglas-Peucker (geometric significance preservation)
- Alternative method: Uniform Sampling (even spacing reduction)
- Range: 0-90% reduction, disabled at 0%
- LAB data processing: Operates on original sparse measurements (0%, 5%, 10%, etc.)
- .cube data processing: Operates on original file sample points
- Control point output: Always generates sparse points to enable interpolation methods

CHANNEL MANAGEMENT SYSTEM:
- State control: Enable/disable via checkbox interface
- Disabled channel behavior: Value set to 0, previous state stored
- Function scope: Apply-to-all operations exclude disabled channels
- UI feedback: Opacity reduction and compact layout for disabled states

FILE FORMAT SPECIFICATIONS:
- .quad: 256-point curve datasets (bidirectional input/output)
- 1DLUT (.cube): 1D LUT linearization correction data
- 3DLUT (.cube): 3D LUT with neutral axis extraction for linearization
- LAB data (.txt): Color Muse measurement datasets for linearization
- .acv: Discontinued in v1.2 (insufficient open-source compatibility)

LINEARIZATION DATA PROCESSING:
- Global LAB data: Applied uniformly to all ink channels via single correction curve
- Per-channel LAB data: Individual correction curves per ink channel for precise control
- 3D LUT processing: Neutral axis extraction (R=G=B diagonal) via trilinear interpolation
- LAB coordinate transformation: Dual transformation applied to measurement data
- File processing: parseLinearizationFile() routes files through appropriate parsers
- 3D LUT extraction: Samples 256 points along neutral axis, ignores color information
- Data validation: Format detection and comprehensive error handling
- Coordinate systems: All formats normalized to quadGEN's printing coordinate system

================================================================================
VERSION HISTORY
================================================================================

v1.4.1 (2025-08-29) - Smoothing Algorithm Refinements:
ADDED:
- Smoothing Splines algorithm: Mathematical curve smoothing with automatic lambda parameter selection
- Visual curve comparison: Original curve overlay (gray dashed line) shows smoothing effects on all channels
- Visvalingam-Whyatt algorithm: Area-based curve simplification (implemented but hidden from UI)
REFINED:
- Streamlined algorithm selection: Removed Ramer-Douglas-Peucker due to inconsistent results
- Simplified interpolation options: Hidden Cubic Spline and Catmull-Rom from UI to reduce complexity
- Default algorithm changed: Uniform Sampling now default with Smoothing Splines as advanced option
- UI cleanup: Removed monotonicity preservation option (PCHIP handles this appropriately)
IMPROVED:
- Curve visualization: Original vs smoothed comparison works with multiple channels simultaneously
- Algorithm focus: Concentrated on reliable, predictable smoothing methods for production use

v1.4 (2025-08-29) - 3D LUT Support & Per-Channel LAB Data:
ADDED:
- 3D LUT neutral axis extraction: Automatic processing of 3D .cube files via trilinear interpolation
- Per-channel LAB data support: Individual Color Muse .txt file loading per ink channel
- Dual format support: Per-channel linearization now accepts both .cube and .txt files
- Individual channel precision: Apply LAB corrections to specific inks for fine-tuned control
- 3D LUT format detection: Automatic routing between 1D and 3D LUT parsers
FIXED:
- Linear interpolation now properly handles non-evenly spaced control points
- LAB data smoothing now works correctly with both Douglas-Peucker and Uniform methods
- LAB data now uses interpolation methods immediately upon loading (no smoothing required)
- Douglas-Peucker algorithm coordinate handling fixed for different data types
- Curve simplification data type mismatch resolved for LAB measurement data
ENHANCED:
- Added Ramer-Douglas-Peucker algorithm as default curve simplification method
- Sample data now bundled in application (LAB measurements and Gamma 2.2 curve)
- UI layout reorganized into compact two-column design for better space utilization
- Sample data buttons now include download functionality for external use
- Consistent dropdown styling applied across all UI elements
TECHNICAL:
- 3D LUT neutral axis extraction uses trilinear interpolation with coordinate system normalization
- Per-channel LAB processing reuses proven parseLinearizationFile() architecture
- Removed explicit .txt file blocking from per-channel linearization function
- 3D LUT processing preserves existing 1D LUT pipeline without modifications
- LAB data getSmoothingControlPoints always returns control points for interpolation
- Linear interpolation uses interval search for non-evenly spaced lutX coordinates
- Douglas-Peucker preserves geometric significance vs uniform sampling's even spacing
- Control points generated from original measurements, not pre-interpolated 256-point curves
================================================================================
v1.3 (2025-08-28) - Linearization Correction Fix:
FIXED:
- Color Muse linearization correction algorithm now matches industry standard
- Manual L* data entry linearization correction algorithm now matches industry standard  
- .cube file linearization corrected to use original samples directly
- Dual coordinate transformation applied to measurement data (Color Muse .txt files and manual L* entry)
- Removed erroneous inverse mapping logic from .cube file parsing

TECHNICAL:
- Color Muse & Manual L* Entry: Applied horizontal and vertical flip transformations
- .cube files: Use original samples without any coordinate transformation
- Different file types require different coordinate system treatments
- Added comprehensive documentation explaining why different treatments are necessary

VALIDATION:
- Empirically validated against industry standard tools using Color-Muse-Data.txt
- All linearization methods now produce correct industry-standard behavior

v1.2 (2025-01-27) - Major Feature Release:
ADDED:
- Complete .quad file loading with curve preservation
- Layered processing system (base curves + linearization)
- Enhanced file validation and error handling
- Info popup with version information
- Compact UI controls and improved UX

CHANGED:
- Merged P700/P900 into single "P700-P900" option (identical 10-channel config)
- Interpolation controls now properly disabled for loaded .quad files
- Apply-to-all functions respect disabled channel checkboxes
- Enhanced scrollbar styling for file preview (24px, bright white, 60px min)

REMOVED:
- ACV file support (Photoshop curve files)
- Smoothing intensity controls (pure interpolation preferred)

TECHNICAL:
- Loaded .quad data stored in loadedQuadData global variable
- make256() function checks for loaded curves before generating linear ramps
- hasAnyLinearization() determines when interpolation controls are relevant
- updateInterpolationControls() manages UI state and visual feedback

v1.1 (Previous):
- Catmull-Rom spline interpolation with tension parameter
- Channel memory system for disabled channels
- Cube file inverse mapping corrections
- Tension controls for spline customization

v1.0 (Initial):
- Basic linear ramp generation
- Printer configuration support
- File download functionality
- Chart visualization

================================================================================
IMPLEMENTATION SPECIFICATIONS
================================================================================

CURVE DATA PROCESSING:
- Linear ramp generation: Mathematical progression 0‚ÜíendValue across 256 steps
- Loaded curve scaling: Proportional adjustment upon ink limit modification
- Linearization application: Lookup table transformation methodology
- Value constraints: 0-65535 range compliance (QuadToneRIP specification)

INTERPOLATION PROCESSING:
- Application scope: Sparse control point linearization data only
- Processing method: apply1DLUT() function implementation
- Mapping algorithm: Forward input value ‚Üí LUT lookup ‚Üí output value
- Algorithm impact: Method selection affects sparse data expansion characteristics

SMOOTHING (DATA POINT REDUCTION):
- Implementation: CurveSimplification object with multiple algorithm support
- Control interface: Horizontal slider (0-90%) positioned under simplification method dropdown
- Available methods: Uniform Sampling (even distribution) and Ramer-Douglas-Peucker (shape-preserving, default)
- Uniform sampling: Preserves start/end points, reduces intermediate points with even spacing
- Ramer-Douglas-Peucker: Shape-preserving algorithm using perpendicular distance tolerance for optimal point selection
- Coordinate system handling: Maintains dual transformation for LAB data, preserves .cube coordinate relationships
- Processing pipeline: originalDataPoints ‚Üí method selection ‚Üí smoothing ‚Üí sparse control points ‚Üí interpolation ‚Üí 256-point curve
- Control point generation: LAB data creates inverse mapping with dual transformation applied to control points
- File type support: LAB data (.txt) files, manual L* entry, 1DLUT (.cube) files, built-in sample data
- Algorithm switching: Real-time method selection with immediate preview update
- Sample data integration: Color Muse measurement sample (21 points) and Gamma 2.2 curve sample (11 points)
- Coordinate preservation: Douglas-Peucker maintains original X positions for .cube data to prevent interpolation artifacts
- Notification system: Non-intrusive overlay notification at top of graph when smoothing is active

CHANNEL STATE ARCHITECTURE:
- Channel properties: Percentage value, end value, enable/disable state
- Value synchronization: Percentage-end value computational relationship maintained
- Disabled channel handling: Checkbox unchecked, values = 0, previous state stored
- Memory management: channelPreviousValues object maintains restoration data

UI STATE CONTROL:
- Interpolation control state: Determined by hasAnyLinearization() function
- File information display: Activated for loaded .quad file datasets
- User feedback system: Status message communication protocol
- Interface documentation: Tooltip-based control functionality explanation
- Layout organization: Two-column interpolation panel (method selection left, smoothing controls right)
- Dropdown standardization: Unified .standard-dropdown CSS class for consistent styling
- Notification overlay: Fixed-position smoothing notification prevents layout shifts

FILENAME GENERATION ALGORITHM:
- Automatic generation: PrinterModel_Ch1Value_Ch2Value... pattern
- User override capability: Manual editing with userEdited flag
- Loaded file handling: originalname_copy default naming convention
- Filesystem compatibility: Character sanitization processing

================================================================================
TESTING NOTES
================================================================================

KEY TEST SCENARIOS:
1. Load .quad file ‚Üí verify curve preservation and limit scaling
2. Load .quad + add linearization ‚Üí verify layered processing
3. Enable/disable channels ‚Üí verify apply-to-all skips disabled
4. Switch printers ‚Üí verify channel count and layout changes
5. File validation ‚Üí verify error handling for corrupted/invalid files
6. LAB data smoothing ‚Üí verify no curve flipping, all interpolation methods functional
7. .cube file smoothing ‚Üí verify coordinate system preservation and Douglas-Peucker X-position accuracy
8. Smoothing + interpolation ‚Üí verify Linear/Cubic/Catmull-Rom/PCHIP compatibility
9. UI layout responsiveness ‚Üí verify two-column interpolation panel and overlay notifications
10. Sample data integration ‚Üí verify Color Muse and Gamma 2.2 curve samples load correctly

EDGE CASES:
- Empty .quad files or corrupted data
- Linearization files with invalid ranges
- Channel limit changes on loaded curves
- Printer switching with loaded data
- File size limits and validation

================================================================================
LINEARIZATION CORRECTION PROCESSING
================================================================================

COORDINATE SYSTEM ANALYSIS: Correction curve implementation requires coordinate transformation distinct from mathematical intuition.

COLOR MUSE DATA PROCESSING:
- Input format: GRAY% (0-100) ‚Üí LAB_L* (measured lightness values)
- Mathematical interpretation: GRAY% input produces LAB_L* output
- Industry standard implementation: Coordinate transformation required

ALGORITHM IMPLEMENTATION BY FILE TYPE:

COLOR MUSE (.txt) & MANUAL L* ENTRY PROCESSING:
1. Density value conversion: L* inversion (high L* = light = low density)
2. Density mapping generation: targetDensity (GRAY%) ‚Üí actualDensity (L*)
3. Correction curve computation: Input determination for target density
4. Dual transformation application:
   - Horizontal flip: flippedInputPos = 1.0 - inputPos (coordinate mirror)
   - Vertical flip: verticallyFlipped = 1.0 - originalSample (value inversion)

CUBE FILE (.cube) PROCESSING:
1. 1D LUT sample extraction from file structure
2. Dual transformation application for coordinate system alignment:
   - Horizontal flip: Coordinate position reversal (ink-RGB relationship)
   - Vertical flip: Value inversion (printing intensity compatibility)
3. Transformation requirement: Industry standard application compatibility

DUAL TRANSFORMATION NECESSITY:
- Implementation consistency: All linearization methods employ identical transformation
- .cube files: RGB‚Üíprinting ink coordinate space conversion required
- Color Muse data: Raw measurement coordinate system interpretation
- Manual L* data: Laboratory measurement coordinate interpretation identical
- Industry compatibility: Standard coordinate system differs from mathematical intuition
- Transformation absence: Incorrect curve topology and crossing point behavior
- Transformation presence: Industry-standard curve behavior achieved

CUBE FILE COORDINATE SYSTEM SPECIFICATION:
- .cube RGB system: index 0 = white (RGB 255), index end = black (RGB 0)
- Printing ink system: 0% ink = white paper, 100% ink = black
- Horizontal transformation: .cube end ‚Üí 0% ink, .cube start ‚Üí 100% ink
- Vertical transformation: .cube value inversion for ink limit implementation
- Implementation example: test-half.cube RGB 50% ‚Üí 0% ink 50% limit, 100% ink 100% limit

VALIDATION METHODOLOGY:
- test-linear.cube: Straight diagonal output (null effect confirmation)
- test-half.cube: 0% ink 50% limit ‚Üí 100% ink 100% limit progression
- test-gamma.cube: Characteristic gamma curve topology (60% crossing point)
- Industry validation: Photoshop RGB 255 ‚Üí RGB 127 behavior replication

TECHNICAL FINDINGS:
1. Coordinate interpretation significance exceeds mathematical complexity
2. Industry standards override intuitive coordinate systems
3. Empirical validation against established tools required
4. Coordinate transformation priority over algorithm selection
5. Historical workflow conventions influence digital implementation

================================================================================
USER WORKFLOW PROCEDURES
================================================================================

OPERATIONAL SEQUENCE:
1. .quad file creation: Specify target ink configuration and initial ink limit values
2. Test target printing: Execute print using specified .quad file with initial ink limits
3. Measurement data acquisition: Color Muse device measurement OR 1DLUT (.cube) file generation via EDN system (http://www.easydigitalnegatives.com/)
4. Data importation: LAB data (.txt) file, manual L* entry, or 1DLUT (.cube) application to initial ink configuration
5. Result verification: Curve graph preview and tonal shape validation
6. Optional adjustment: Channel limit modification (enable/disable inks, uniform percentage application)
7. File export: Corrected .quad file generation and QuadToneRIP integration
8. Validation procedure: Reprint execution with corrected .quad file, tonal reproduction target matching verification

WORKFLOW INTEGRATION:
- QuadToneRIP ecosystem compatibility maintained throughout process
- Iterative refinement capability through measurement-correction cycles
- Alternative measurement methodologies supported (Color Muse, EDN system)
- Advanced user flexibility via optional adjustment procedures

================================================================================
FUTURE CONSIDERATIONS
================================================================================

POTENTIAL ENHANCEMENTS:
- Additional printer model support
- Batch processing capabilities  
- Curve comparison tools
- Export format options
- Advanced curve editing features

ARCHITECTURAL NOTES:
- Single HTML file approach for simplicity and portability
- Client-side processing (no server dependencies)
- Tailwind CSS for styling consistency
- Vanilla JavaScript for maximum compatibility

================================================================================
-->

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title id="pageTitle">quadGEN</title>
  <meta name="description" content="quadGEN - Generate Epson P700-P900/P800 QuadToneRIP .quad files with 256-step ramps per channel." />
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    /* Always show number input arrows */
    input[type="number"]::-webkit-outer-spin-button,
    input[type="number"]::-webkit-inner-spin-button {
      -webkit-appearance: inner-spin-button !important;
      opacity: 1 !important;
    }
    
    input[type="number"] {
      -moz-appearance: textfield;
    }
    
    input[type="number"]::-moz-number-spin-box {
      -moz-appearance: spin-textfield !important;
    }

    /* Slider toggle styles */
    .slider-toggle {
      position: relative;
      display: inline-block;
      width: 40px;
      height: 20px;
    }

    .slider-toggle input {
      opacity: 0;
      width: 0;
      height: 0;
    }

    .slider {
      position: absolute;
      cursor: pointer;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background-color: #ccc;
      transition: .4s;
      border-radius: 20px;
    }

    .slider:before {
      position: absolute;
      content: "";
      height: 16px;
      width: 16px;
      left: 2px;
      bottom: 2px;
      background-color: white;
      transition: .4s;
      border-radius: 50%;
    }

    input:checked + .slider {
      background-color: #10b981;
    }

    input:focus + .slider {
      box-shadow: 0 0 1px #10b981;
    }

    input:checked + .slider:before {
      transform: translateX(20px);
    }

    input:disabled + .slider {
      background-color: #e5e5e5;
      cursor: not-allowed;
    }

    input:disabled + .slider:before {
      background-color: #f5f5f5;
    }

    /* Custom checkbox styling with white checkmark */
    .channel-enable-checkbox {
      appearance: none;
      width: 16px;
      height: 16px;
      border: 2px solid #d1d5db;
      border-radius: 3px;
      background-color: white;
      cursor: pointer;
      position: relative;
    }
    
    .channel-enable-checkbox:checked {
      background-color: #10b981;
      border-color: #10b981;
    }
    
    .channel-enable-checkbox:checked::after {
      content: '‚úì';
      color: white;
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      font-size: 12px;
      font-weight: bold;
    }

    /* Custom scrollbar styling for file preview */
    #previewFull::-webkit-scrollbar {
      width: 24px;
    }

    #previewFull::-webkit-scrollbar-track {
      background: #2d3748;
      border-radius: 12px;
    }

    #previewFull::-webkit-scrollbar-thumb {
      background: #ffffff;
      border-radius: 12px;
      border: 3px solid #2d3748;
      min-height: 60px;
    }

    #previewFull::-webkit-scrollbar-thumb:hover {
      background: #f7fafc;
    }

    #previewFull::-webkit-scrollbar-thumb:active {
      background: #e2e8f0;
    }

    /* Instant tooltip for linearization buttons */
    .per-channel-btn, #globalLinearizationBtn {
      position: relative;
    }

    .per-channel-btn:hover::after, #globalLinearizationBtn:hover::after {
      content: attr(data-tooltip);
      position: absolute;
      bottom: 100%;
      left: 50%;
      transform: translateX(-50%);
      background-color: #1f2937;
      color: white;
      padding: 4px 8px;
      border-radius: 4px;
      font-size: 12px;
      white-space: nowrap;
      z-index: 1000;
      margin-bottom: 4px;
      pointer-events: none;
    }

    .per-channel-btn:hover::before, #globalLinearizationBtn:hover::before {
      content: '';
      position: absolute;
      bottom: 100%;
      left: 50%;
      transform: translateX(-50%);
      width: 0;
      height: 0;
      border-left: 4px solid transparent;
      border-right: 4px solid transparent;
      border-top: 4px solid #1f2937;
      z-index: 1000;
      pointer-events: none;
    }

    /* Hide number input spinners */
    .lstar-input::-webkit-outer-spin-button,
    .lstar-input::-webkit-inner-spin-button {
      -webkit-appearance: none;
      margin: 0;
    }
    
    .lstar-input[type=number] {
      -moz-appearance: textfield;
    }
    
    /* Standard dropdown styling */
    .standard-dropdown {
      width: 100%;
      padding: 0.25rem 0.75rem;
      border: 1px solid #d1d5db;
      border-radius: 0.375rem;
      font-size: 0.875rem;
      line-height: 1.25;
      height: 32px;
      box-sizing: border-box;
      background-color: white;
      color: #374151;
    }
    
    .standard-dropdown:disabled {
      background-color: #f9fafb;
      color: #9ca3af;
      cursor: not-allowed;
    }
    
    .standard-dropdown option {
      font-size: 0.875rem;
      line-height: 1.25;
      color: #374151;
    }
  </style>
</head>
<body class="min-h-screen bg-gray-50 p-6">
  <main class="mx-auto max-w-6xl">
    <section class="bg-white rounded-2xl shadow-lg p-6 md:p-8">
      <header class="mb-6">
        <div class="grid grid-cols-1 lg:grid-cols-3 gap-6 items-center mb-2">
          <div class="flex items-center gap-4 lg:col-span-3">
            <svg id="quadgenLogo" xmlns="http://www.w3.org/2000/svg" width="56" height="56" viewBox="0 0 160 160" role="img" aria-labelledby="quadgenTitle quadgenDesc">
              <title id="quadgenTitle">quadGEN icon (CMYK)</title>
              <desc id="quadgenDesc">Four CMYK bars with a rising Bezier-style curve and nodes, flat design.</desc>
              <!-- baseline -->
              <path d="M16 132H144" fill="none" stroke="#1A1A1A" stroke-width="8" stroke-linecap="round"/>
              <!-- CMYK bars -->
              <rect id="cyanBar" x="20" y="90" width="20" height="40" rx="6" ry="6" fill="#00B5E2"/>
              <rect id="magentaBar" x="52" y="70" width="20" height="60" rx="6" ry="6" fill="#FF2A8A"/>
              <rect id="yellowBar" x="84" y="50" width="20" height="80" rx="6" ry="6" fill="#FFD400"/>
              <rect id="blackBar" x="116" y="22" width="20" height="110" rx="6" ry="6" fill="#1A1A1A"/>
              <!-- Bezier-like curve -->
              <path id="logoPath" d="M30 88 C 44 84, 50 72, 62 68 S 86 50, 94 48 S 118 28, 126 18"
                    fill="none" stroke="#1A1A1A" stroke-width="8" stroke-linecap="round" stroke-linejoin="round"/>
              <!-- curve nodes -->
              <circle id="node1" cx="30" cy="88" r="6" fill="white" stroke="#1A1A1A" stroke-width="2"/>
              <circle id="node2" cx="62" cy="68" r="6" fill="white" stroke="#1A1A1A" stroke-width="2"/>
              <circle id="node3" cx="94" cy="48" r="6" fill="white" stroke="#1A1A1A" stroke-width="2"/>
              <circle id="node4" cx="126" cy="18" r="6" fill="white" stroke="#1A1A1A" stroke-width="2"/>
            </svg>
            <div>
              <h1 class="text-2xl md:text-3xl font-semibold tracking-tight">
                quadGEN
                <span id="appVersion" class="text-gray-400 text-lg"></span>
              </h1>
              <p class="text-gray-400 text-sm -mt-1">by <a href="https://www.davidmarshprints.com/" target="_blank" rel="noopener noreferrer" class="hover:text-gray-600 underline">David Marsh</a></p>
            </div>
            
            <!-- Compact printer selector -->
            <div class="flex items-center gap-2 bg-gray-50 rounded-lg border border-gray-200 px-3 py-2 flex-1 ml-4">
              <label for="printerSelect" class="text-sm font-medium text-gray-700">Printer:</label>
              <select id="printerSelect" class="standard-dropdown" style="width: 120px;">
                <option value="P800">P800</option>
                <option value="P700P900" selected>P700-P900</option>
              </select>
              <p id="channelInfo" class="text-xs text-gray-600 ml-1" style="width: 280px;"></p>
              <button id="infoBtn" class="text-xs text-gray-400 hover:text-gray-600 bg-gray-100 hover:bg-gray-200 rounded px-2 py-1 transition-colors ml-auto font-bold" title="Version info">
                About
              </button>
            </div>
          </div>
          
        </div>
        <p id="printerDescription" class="text-gray-600 mt-1"></p>
      </header>

      <!-- Ink Limits Graph and Linearization -->
      <div class="mb-6 grid grid-cols-1 lg:grid-cols-3 gap-6">
        <!-- Graph Section -->
        <div class="lg:col-span-2 space-y-4">
          <div class="bg-white border border-gray-200 rounded-xl p-4 relative">
            <div class="bg-gray-50 rounded-lg p-4">
              <canvas id="inkChart" width="950" height="700" class="w-full h-auto max-h-none"></canvas>
            </div>
            
            <!-- Status Display -->
            <div class="absolute top-4 left-4 right-4 z-10">
              <div class="bg-gray-50 rounded-lg px-3 py-2 text-center flex items-center justify-center">
                <span id="status" class="text-xs text-gray-600 font-medium transition-opacity duration-500 ease-in-out">&nbsp;</span>
              </div>
            </div>
            
            <!-- Smoothing Note Overlay -->
            <div id="smoothingWarning" class="absolute bottom-4 left-4 right-4 text-xs text-amber-800 text-center hidden">
              ‚ÑπÔ∏è Note: Smoothing allows departure of curves from loaded data
            </div>
          </div>
          
          <!-- Interpolation Method -->
          <div class="bg-white border border-gray-200 rounded-xl p-3">
            <div class="grid grid-cols-1 lg:grid-cols-2 gap-6">
              <!-- Left Column: Interpolation Method -->
              <div class="space-y-3">
                <h3 class="text-sm font-medium text-gray-700">Interpolation Method</h3>
                <div>
                  <select id="curveSmoothingMethod" class="standard-dropdown" disabled>
                    <option value="pchip" selected>PCHIP (monotonic)</option>
                    <option value="linear">Linear (none)</option>
                  </select>
                  <p id="interpolationDescription" class="text-xs text-gray-500 mt-2">Monotonic interpolation preserves data trends</p>
                </div>
                
                <!-- Catmull-Rom Tension Control -->
                <div id="catmullTensionContainer" style="display: none;">
                  <label class="block text-sm font-medium text-gray-700 mb-1">Curve Tension</label>
                  <div class="flex items-center gap-2">
                    <span class="text-xs text-gray-500">Tight</span>
                    <input type="range" id="catmullTension" min="0" max="100" value="50" class="flex-1 h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer" disabled>
                    <span class="text-xs text-gray-500">Loose</span>
                  </div>
                  <p class="text-xs text-gray-500 mt-1">Adjust how curvy the interpolation becomes</p>
                </div>
              </div>
              
              <!-- Right Column: Data Point Smoothing -->
              <div class="space-y-3">
                <h3 class="text-sm font-medium text-gray-700">Data Point Smoothing: <span id="smoothingValue" class="text-xs text-gray-500">0%</span></h3>
                <div>
                  <select id="simplificationMethod" class="standard-dropdown" disabled>
                    <option value="uniform" selected>Uniform Sampling</option>
                    <option value="smoothing-splines">Smoothing Splines</option>
                  </select>
                </div>
                
                <!-- Smoothing Slider -->
                <div class="flex items-center gap-2">
                  <span class="text-xs text-gray-500">0%</span>
                  <input type="range" id="smoothingSlider" min="0" max="90" value="0" class="flex-1 h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer" disabled>
                  <span class="text-xs text-gray-500">90%</span>
                </div>
              </div>
            </div>
          </div>
        </div>
        
        <!-- Linearization Section -->
        <div class="lg:col-span-1 space-y-4">
          <!-- Global Linearization -->
          <div class="bg-white border border-gray-200 rounded-xl p-3">
            <h3 class="text-lg font-semibold mb-2">Global Linearization Data</h3>
            <p class="text-xs text-gray-600 mb-2">Apply correction to modify all ink channels uniformly.</p>
            
            <div class="bg-white border border-gray-200 rounded-lg p-2 mb-3">
              <p class="text-xs text-gray-700 font-medium mb-1">Linearization Options:</p>
              <p class="text-xs text-gray-600">
                <strong>LAB data (.txt):</strong> Raw measurements ‚Üí calculates correction curve<br>
                <strong>LUT (.cube):</strong> Pre-made correction curves ‚Üí applies directly<br>
                <strong>Manual L* Entry:</strong> Enter measured L* values directly (see button below)
              </p>
            </div>
            
            <!-- Linearization Controls -->
            <div class="space-y-3">              
              <!-- File Upload -->
              <div>
                <label class="block text-sm font-medium text-gray-700 mb-1">Data Source</label>
                <div id="globalLinearizationInfo" class="text-xs text-gray-600 mb-2 hidden">
                  <span id="globalLinearizationFilename" class="font-medium"></span>
                  <span id="globalLinearizationDetails" class="text-gray-500"></span>
                </div>
                <div class="inline-flex items-center gap-2">
                  <input type="file" id="linearizationFile" accept=".cube,.txt" class="hidden">
                  <button id="globalLinearizationBtn" class="px-2 py-1 text-xs bg-gray-100 hover:bg-gray-200 text-gray-600 rounded transition-colors font-bold" data-tooltip="Load LUT.cube or LABdata.txt files">load file</button>
                  <label class="slider-toggle" title="Enable/disable global linearization">
                    <input type="checkbox" id="globalLinearizationToggle" disabled>
                    <span class="slider"></span>
                  </label>
                </div>
                <p class="text-xs text-gray-500 mt-1">accepts LUT (.cube) or LAB data (.txt) files</p>
              </div>
            </div>
            
            <!-- Manual L* Entry Button -->
            <div class="mt-3 pt-3 border-t border-gray-200">
              <button id="manualLstarBtn" class="w-full px-3 py-2 text-sm bg-green-100 hover:bg-green-200 text-green-700 rounded transition-colors font-bold">
                ‚úèÔ∏è Enter L* values manually
              </button>
            </div>

            <!-- Sample Data -->
            <div class="mt-3 pt-3 border-t border-gray-200">
              <label class="block text-sm font-medium text-gray-700 mb-2">Sample Data</label>
              <div class="flex gap-1">
                <div class="flex-1">
                  <button id="loadSampleColorMuse" class="w-full px-2 py-1 text-xs bg-blue-100 hover:bg-blue-200 text-blue-700 rounded transition-colors font-bold">
                    Load sample LABdata.txt
                  </button>
                  <a id="downloadSampleColorMuse" href="#" class="block text-center text-xs text-blue-600 hover:text-blue-800 mt-1">Download file</a>
                </div>
                <div class="flex-1">
                  <button id="loadSampleCube" class="w-full px-2 py-1 text-xs bg-purple-100 hover:bg-purple-200 text-purple-700 rounded transition-colors font-bold">
                    Load sample LUT.cube
                  </button>
                  <a id="downloadSampleCube" href="#" class="block text-center text-xs text-purple-600 hover:text-purple-800 mt-1">Download file</a>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>


      <!-- Channel table -->
      <div class="mt-6 overflow-auto">
        <table class="w-full text-sm border border-gray-200 rounded-xl overflow-hidden">
          <thead>
            <!-- Apply to all controls row -->
            <tr class="bg-white border-b border-gray-200">
              <th class="px-1 py-2">
                <input type="file" id="quadFile" accept=".quad" class="hidden">
                <button id="loadQuadBtn" class="w-full px-3 py-2 text-sm bg-blue-100 hover:bg-blue-200 text-blue-700 rounded transition-colors font-bold">
                  üíæ Load .quad
                </button>
              </th>
              <th class="px-3 py-2" style="width: 200px;">
                <span id="quadFileInfo" class="text-xs text-gray-500 hidden block truncate" style="width: 100%;">No file loaded</span>
              </th>
              <th class="px-1 py-2"></th>
              <th class="px-1 py-2">
                <div class="flex gap-1">
                  <input id="applyPercent" type="number" step="1" min="0" max="100" value="33" class="w-20 rounded border border-gray-300 px-2 py-1 text-sm focus:outline-none focus:ring-2 focus:ring-black/10 focus:border-gray-400" />
                  <button id="btnApplyPercent" class="rounded px-3 py-1 text-xs bg-black text-white hover:bg-black/90">‚Üì Apply all</button>
                </div>
              </th>
              <th class="px-1 py-2">
                <div class="flex gap-1">
                  <input id="applyEnd" type="number" step="1" min="0" max="64000" value="21120" class="w-20 rounded border border-gray-300 px-2 py-1 text-sm focus:outline-none focus:ring-2 focus:ring-black/10 focus:border-gray-400" />
                  <button id="btnApplyEnd" class="rounded px-3 py-1 text-xs bg-black text-white hover:bg-black/90">‚Üì Apply all</button>
                </div>
              </th>
            </tr>
            <tr class="bg-gray-50 text-gray-700">
              <th class="text-center px-1 py-2">
                <button id="disableAllBtn" class="px-2 py-1 text-xs bg-red-100 text-red-700 hover:bg-red-200 rounded transition-colors font-bold" title="Disable all channels (set all to 0)">
                  Disable All
                </button>
              </th>
              <th class="text-left px-1 py-2">Channel</th>
              <th class="text-left px-1 py-2" style="width: 140px;">Curve</th>
              <th class="text-left px-1 py-2">Percent (0‚Äì100)</th>
              <th class="text-left px-1 py-2">End (0‚Äì64,000)</th>
            </tr>
          </thead>
          <tbody id="rows"></tbody>
        </table>
      </div>

      <!-- Actions -->
      <div class="mt-6">
        <div class="flex items-center gap-2">
          <button id="downloadBtn" class="inline-flex items-center justify-center rounded-lg px-5 py-2 font-medium shadow-sm bg-black text-white hover:bg-black/90">
            ‚Üì Download .quad
          </button>
          <label for="filenameInput" class="text-sm font-medium text-gray-700">Filename:</label>
          <input id="filenameInput" type="text" placeholder="P900_K33_C33_M33..." class="flex-1 rounded-lg border border-gray-300 px-3 py-2 text-sm focus:outline-none focus:ring-2 focus:ring-black/10 focus:border-gray-400" />
          <span class="text-sm text-gray-500">.quad</span>
        </div>
      </div>

      <!-- Configuration Notes -->
      <div class="mt-6">
        <div class="bg-white border border-gray-200 rounded-xl p-2">
          <div class="flex items-center gap-2">
            <button id="notesToggle" class="px-2 py-1 bg-gray-100 hover:bg-gray-200 text-gray-600 hover:text-gray-800 rounded transition-colors font-bold" title="Expand/collapse notes">
              <svg id="notesChevron" class="w-4 h-4 transform transition-transform duration-200" style="transform: rotate(0deg)" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"></path>
              </svg>
            </button>
            <h3 class="text-sm font-medium text-gray-700">Configuration Notes</h3>
          </div>
          
          <div id="notesContent" class="hidden">
            <div>
              <textarea id="userNotes" placeholder="Add notes to be added as comments to the generated .quad file" class="w-full rounded-lg border border-gray-300 px-3 py-2 text-sm focus:outline-none focus:ring-2 focus:ring-black/10 focus:border-gray-400 resize-none" rows="4"></textarea>
            </div>
          </div>
        </div>
      </div>

      <!-- Full Preview -->
      <div class="mt-8">
        <div class="border border-gray-200 rounded-xl overflow-hidden">
          <div class="bg-gray-100 px-4 py-2 text-sm font-medium text-gray-700">.quad File Preview</div>
          <pre id="previewFull" class="p-4 text-sm leading-6 overflow-auto max-h-[70vh] bg-black text-white font-mono">‚Äì</pre>
        </div>
      </div>
    </section>
    
    <!-- Info Popup -->
    <div id="infoPopup" class="fixed inset-0 bg-black bg-opacity-50 hidden z-50 flex items-center justify-center p-4">
      <div class="bg-white rounded-xl max-w-4xl w-full max-h-[90vh] p-6 relative">
        <button id="closeInfoBtn" class="absolute top-4 right-4 text-gray-400 hover:text-gray-600 transition-colors">
          <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path>
          </svg>
        </button>
        
        <h2 id="infoPopupTitle" class="text-xl font-bold mb-4">quadGEN</h2>
        
        <div id="changelogContent" class="text-sm text-gray-700 space-y-4 max-h-[70vh] overflow-y-auto">
          <!-- Changelog will be dynamically populated from main documentation -->
        </div>
      </div>
    </div>
  </main>

  <!-- Manual L* Entry Modal -->
  <div id="lstarModal" class="fixed inset-0 bg-black bg-opacity-50 hidden flex items-center justify-center z-50">
    <div class="bg-white rounded-lg max-w-md w-full mx-4 max-h-[80vh] flex flex-col">
      <!-- Fixed Header -->
      <div class="p-6 pb-4 flex-shrink-0">
        <div class="flex justify-between items-center mb-4">
          <h3 class="text-lg font-semibold">Manual Luminosity (L*) Entry</h3>
          <button id="closeLstarModal" class="text-gray-500 hover:text-gray-700 text-xl">&times;</button>
        </div>
        
        <div class="mb-4 text-sm text-gray-600">
          <p>Enter L* values from your measurements. Values should be evenly spaced from white to black.</p>
          <div class="flex justify-between mt-2 text-xs">
            <span class="text-gray-400">‚ö™ White (L*=100)</span>
            <span class="text-gray-600">‚ö´ Black (L*=0)</span>
          </div>
        </div>

        <div class="flex items-center justify-between mb-4 p-3 bg-gray-50 rounded border">
          <div class="flex gap-2">
            <button id="addLstarInput" class="px-3 py-1 text-sm bg-green-100 hover:bg-green-200 text-green-700 rounded font-bold">+ Add</button>
            <button id="removeLstarInput" class="px-3 py-1 text-sm bg-red-100 hover:bg-red-200 text-red-700 rounded font-bold">- Remove</button>
          </div>
          <div class="flex items-center gap-2">
            <label class="text-sm text-gray-600">Fields:</label>
            <input type="number" id="lstarCountInput" min="3" max="50" value="5" class="w-16 px-2 py-1 text-sm border border-gray-300 rounded focus:outline-none focus:ring-1 focus:ring-green-500 focus:border-green-500">
          </div>
        </div>
      </div>

      <!-- Scrollable Content -->
      <div class="flex-1 overflow-y-auto px-6">
        <div class="flex gap-4 mb-4">
          <!-- Gradient Bar -->
          <div class="w-12 bg-gradient-to-b from-white to-black rounded border border-gray-300 relative">
            <div class="absolute inset-0 flex flex-col justify-between text-xs text-gray-600 py-2">
              <div class="text-center bg-white bg-opacity-75 px-1 rounded">100</div>
              <div class="text-center bg-black bg-opacity-75 text-white px-1 rounded">0</div>
            </div>
          </div>
          
          <!-- L* Input Fields -->
          <div class="flex-1">
            <div id="lstarInputs" class="space-y-2">
              <!-- Dynamic inputs will be added here -->
            </div>
          </div>
        </div>

        <div id="lstarValidation" class="text-sm text-red-600 mb-4 hidden"></div>
      </div>

      <!-- Fixed Footer -->
      <div class="p-6 pt-4 flex-shrink-0 border-t border-gray-200">
        <div class="flex justify-end gap-3">
          <button id="cancelLstar" class="px-4 py-2 text-gray-600 hover:text-gray-800 bg-gray-100 hover:bg-gray-200 rounded font-bold">Cancel</button>
          <button id="generateFromLstar" class="px-4 py-2 bg-green-600 hover:bg-green-700 text-white rounded">Generate Correction</button>
        </div>
      </div>
    </div>
  </div>

  <script>
    // Application version - update in one place
    const APP_VERSION = 'v1.4.1';
    
    const TOTAL = 64000;
    const N = 256;
    const DENOM = N - 1;

    const PRINTERS = {
      P800: { name: "Epson P800", channels: ["K","C","M","Y","LC","LM","LK","LLK"] },
      P700P900: { name: "Epson P700-P900", channels: ["K","C","M","Y","LC","LM","LK","LLK","V","MK"] }
    };

    const INK_COLORS = {
      K: "#111111",
      C: "#00AEEF",
      M: "#EC008C",
      Y: "#FFF200",
      LC: "#8FD3FF",
      LM: "#FF9AD5",
      LK: "#777777",
      LLK: "#BBBBBB",
      V: "#7F00FF",
      MK: "#000000"
    };


    // Cache DOM elements
    const elements = {
      rows: document.getElementById('rows'),
      printerSelect: document.getElementById('printerSelect'),
      channelInfo: document.getElementById('channelInfo'),
      printerDescription: document.getElementById('printerDescription'),
      applyPercent: document.getElementById('applyPercent'),
      btnApplyPercent: document.getElementById('btnApplyPercent'),
      applyEnd: document.getElementById('applyEnd'),
      btnApplyEnd: document.getElementById('btnApplyEnd'),
      downloadBtn: document.getElementById('downloadBtn'),
      previewFull: document.getElementById('previewFull'),
      status: document.getElementById('status'),
      inkChart: document.getElementById('inkChart'),
      filenameInput: document.getElementById('filenameInput'),
      linearizationFile: document.getElementById('linearizationFile'),
      globalLinearizationBtn: document.getElementById('globalLinearizationBtn'),
      globalLinearizationToggle: document.getElementById('globalLinearizationToggle'),
      curveSmoothingMethod: document.getElementById('curveSmoothingMethod'),
      catmullTension: document.getElementById('catmullTension'),
      catmullTensionContainer: document.getElementById('catmullTensionContainer'),
      smoothingSlider: document.getElementById('smoothingSlider'),
      smoothingValue: document.getElementById('smoothingValue'),
      smoothingWarning: document.getElementById('smoothingWarning'),
      simplificationMethod: document.getElementById('simplificationMethod'),
      userNotes: document.getElementById('userNotes'),
      notesToggle: document.getElementById('notesToggle'),
      quadFile: document.getElementById('quadFile'),
      loadQuadBtn: document.getElementById('loadQuadBtn'),
      quadFileInfo: document.getElementById('quadFileInfo'),
      manualLstarBtn: document.getElementById('manualLstarBtn'),
      lstarModal: document.getElementById('lstarModal'),
      closeLstarModal: document.getElementById('closeLstarModal'),
      lstarInputs: document.getElementById('lstarInputs'),
      addLstarInput: document.getElementById('addLstarInput'),
      removeLstarInput: document.getElementById('removeLstarInput'),
      lstarCountInput: document.getElementById('lstarCountInput'),
      lstarValidation: document.getElementById('lstarValidation'),
      cancelLstar: document.getElementById('cancelLstar'),
      generateFromLstar: document.getElementById('generateFromLstar'),
      notesContent: document.getElementById('notesContent'),
      notesChevron: document.getElementById('notesChevron'),
      disableAllBtn: document.getElementById('disableAllBtn'),
      infoBtn: document.getElementById('infoBtn'),
      infoPopup: document.getElementById('infoPopup'),
      closeInfoBtn: document.getElementById('closeInfoBtn'),
      interpolationDescription: document.getElementById('interpolationDescription'),
      globalLinearizationInfo: document.getElementById('globalLinearizationInfo'),
      globalLinearizationFilename: document.getElementById('globalLinearizationFilename'),
      globalLinearizationDetails: document.getElementById('globalLinearizationDetails'),
      loadSampleColorMuse: document.getElementById('loadSampleColorMuse'),
      loadSampleCube: document.getElementById('loadSampleCube'),
      pageTitle: document.getElementById('pageTitle'),
      appVersion: document.getElementById('appVersion'),
      infoPopupTitle: document.getElementById('infoPopupTitle'),
    };

    // Initialize dynamic version numbers
    function initializeVersionNumbers() {
      elements.pageTitle.textContent = `quadGEN ${APP_VERSION}`;
      elements.appVersion.textContent = APP_VERSION;
      elements.infoPopupTitle.textContent = `quadGEN ${APP_VERSION}`;
    }

    // Initialize version numbers when DOM is ready
    initializeVersionNumbers();

    // Sample data constants
    const SAMPLE_DATA = {
      colorMuse: `GRAY\tLAB_L\tLAB_A\tLAB_B
0\t97.15\t0.00\t0.00
5\t97.14\t0.00\t0.00
10\t95.90\t0.00\t0.00
15\t93.30\t0.00\t0.00
20\t90.06\t0.00\t0.00
25\t85.89\t0.00\t0.00
30\t79.22\t0.00\t0.00
35\t71.65\t0.00\t0.00
40\t64.43\t0.00\t0.00
45\t58.21\t0.00\t0.00
50\t52.13\t0.00\t0.00
55\t46.63\t0.00\t0.00
60\t41.83\t0.00\t0.00
65\t38.50\t0.00\t0.00
70\t35.63\t0.00\t0.00
75\t31.53\t0.00\t0.00
80\t29.94\t0.00\t0.00
85\t27.34\t0.00\t0.00
90\t25.91\t0.00\t0.00
95\t24.17\t0.00\t0.00
100\t21.33\t0.00\t0.00`,

      gammaCube: `# Test LUT - Gamma 2.2 curve
TITLE "Test Gamma 2.2"
LUT_1D_SIZE 11
DOMAIN_MIN 0.0 0.0 0.0
DOMAIN_MAX 1.0 1.0 1.0

# Gamma 2.2 curve: output = input^2.2
0.0 0.0 0.0
0.01 0.01 0.01
0.05 0.05 0.05
0.13 0.13 0.13
0.24 0.24 0.24
0.41 0.41 0.41
0.61 0.61 0.61
0.78 0.78 0.78
0.90 0.90 0.90
0.97 0.97 0.97
1.0 1.0 1.0`
    };

    // Input validation utilities
    class InputValidator {
      static clampPercent(p) { 
        const num = parseFloat(p);
        return isNaN(num) ? 0 : Math.min(100, Math.max(0, num)); 
      }
      
      static clampEnd(e) { 
        const num = parseInt(e);
        return isNaN(num) ? 0 : Math.min(64000, Math.max(0, num)); 
      }
      
      static computeEndFromPercent(p) { 
        return Math.round((TOTAL * p) / 100); 
      }
      
      static computePercentFromEnd(e) { 
        return (e / TOTAL) * 100; 
      }

      static validateInput(input, validator) {
        const originalValue = input.value;
        const validatedValue = validator(originalValue);
        const isValid = validatedValue.toString() === originalValue || Math.abs(parseFloat(originalValue) - validatedValue) < 0.01;
        
        input.classList.toggle('border-red-300', !isValid);
        input.classList.toggle('border-gray-300', isValid);
        
        if (!isValid) {
          input.value = validatedValue.toString();
        }
        
        return validatedValue;
      }
    }

    // Debounce function to prevent excessive updates
    function debounce(func, wait) {
      let timeout;
      return function executedFunction(...args) {
        const later = () => {
          clearTimeout(timeout);
          func(...args);
        };
        clearTimeout(timeout);
        timeout = setTimeout(later, wait);
      };
    }

    function showStatus(message) {
      elements.status.textContent = message;
      elements.status.style.opacity = '1';
      setTimeout(() => {
        if (elements.status.textContent === message) {
          elements.status.style.opacity = '0';
          setTimeout(() => {
            if (elements.status.style.opacity === '0') {
              elements.status.innerHTML = "&nbsp;";
              elements.status.style.opacity = '1';
            }
          }, 500); // Wait for fade transition to complete
        }
      }, 6000);
    }
    
    function animateLogoBars() {
      const cyanBar = document.getElementById('cyanBar');
      const magentaBar = document.getElementById('magentaBar');
      const yellowBar = document.getElementById('yellowBar');
      const blackBar = document.getElementById('blackBar');
      const logoPath = document.getElementById('logoPath');
      const node1 = document.getElementById('node1');
      const node2 = document.getElementById('node2');
      const node3 = document.getElementById('node3');
      const node4 = document.getElementById('node4');
      
      if (!cyanBar || !magentaBar || !yellowBar || !blackBar) return;
      
      // Original values
      const originalHeights = { cyan: 40, magenta: 60, yellow: 80, black: 110 };
      const originalYs = { cyan: 90, magenta: 70, yellow: 50, black: 22 };
      
      let animationStep = 0;
      const maxSteps = 32; // Number of back-and-forth movements
      
      function animateStep() {
        if (animationStep >= maxSteps) {
          // Final return to original state
          cyanBar.setAttribute('height', originalHeights.cyan);
          cyanBar.setAttribute('y', originalYs.cyan);
          magentaBar.setAttribute('height', originalHeights.magenta);
          magentaBar.setAttribute('y', originalYs.magenta);
          yellowBar.setAttribute('height', originalHeights.yellow);
          yellowBar.setAttribute('y', originalYs.yellow);
          blackBar.setAttribute('height', originalHeights.black);
          blackBar.setAttribute('y', originalYs.black);
          logoPath.setAttribute('d', 'M30 88 C 44 84, 50 72, 62 68 S 86 50, 94 48 S 118 32, 126 22');
          node1.setAttribute('cy', '88');
          node2.setAttribute('cy', '68');
          node3.setAttribute('cy', '48');
          node4.setAttribute('cy', '18');
          return;
        }
        
        // Generate oscillating variations that get smaller over time
        const damping = 1 - (animationStep / maxSteps) * 0.7; // Reduce intensity over time
        const frequency = Math.sin(animationStep * 0.8) * damping; // Oscillating pattern
        
        const cyanVariation = originalHeights.cyan + frequency * 12;
        const magentaVariation = originalHeights.magenta + frequency * 15;
        const yellowVariation = originalHeights.yellow + frequency * 18;
        const blackVariation = originalHeights.black + frequency * 25;
        
        // Update bar heights and positions
        cyanBar.setAttribute('height', Math.max(5, cyanVariation));
        cyanBar.setAttribute('y', 132 - Math.max(5, cyanVariation));
        
        magentaBar.setAttribute('height', Math.max(5, magentaVariation));
        magentaBar.setAttribute('y', 132 - Math.max(5, magentaVariation));
        
        yellowBar.setAttribute('height', Math.max(5, yellowVariation));
        yellowBar.setAttribute('y', 132 - Math.max(5, yellowVariation));
        
        blackBar.setAttribute('height', Math.max(5, blackVariation));
        blackBar.setAttribute('y', 132 - Math.max(5, blackVariation));
        
        // Update curve and nodes to match bar heights
        const newCyanY = 132 - Math.max(5, cyanVariation) + 2;
        const newMagentaY = 132 - Math.max(5, magentaVariation) + 2;
        const newYellowY = 132 - Math.max(5, yellowVariation) + 2;
        const newBlackY = 132 - Math.max(5, blackVariation) + 2;
        
        // Update curve path
        const newPath = `M30 ${newCyanY} C 44 ${newCyanY-4}, 50 ${newMagentaY+4}, 62 ${newMagentaY} S 86 ${newYellowY+2}, 94 ${newYellowY} S 118 ${newBlackY+10}, 126 ${newBlackY}`;
        logoPath.setAttribute('d', newPath);
        
        // Update node positions
        node1.setAttribute('cy', newCyanY);
        node2.setAttribute('cy', newMagentaY);
        node3.setAttribute('cy', newYellowY);
        node4.setAttribute('cy', newBlackY);
        
        animationStep++;
        setTimeout(animateStep, 100); // 100ms between each step
      }
      
      animateStep(); // Start the animation sequence
    }
    

    function updatePreview() {
      requestAnimationFrame(() => {
        try {
          const fileText = buildFile();
          elements.previewFull.textContent = fileText;
          updateInkChart();
          updateFilename(); // Update filename when preview updates
          showStatus("Preview updated");
        } catch (error) {
          console.error('Preview update error:', error);
          showStatus("Error updating preview");
        }
      });
    }

    function updateInkChart() {
      if (elements.rows.children.length === 0) return;
      
      const canvas = elements.inkChart;
      const ctx = canvas.getContext('2d');
      const width = canvas.width;
      const height = canvas.height;
      
      // Clear canvas
      ctx.clearRect(0, 0, width, height);
      
      // Set up coordinate system
      const padding = 60;
      const leftPadding = padding - 6; // Shift chart 6px left
      const rightPadding = padding + 6; // Maintain total width
      const chartWidth = width - leftPadding - rightPadding;
      const chartHeight = height - 2 * padding;
      
      // Check conditions for showing original curve overlay
      const smoothingPercent = parseFloat(elements.smoothingSlider.value) || 0;
      const shouldShowOriginal = smoothingPercent > 0;
      
      // Draw grid
      ctx.strokeStyle = '#e5e7eb';
      ctx.lineWidth = 1;
      
      // Vertical grid lines (every 10%)
      for (let i = 0; i <= 10; i++) {
        const x = leftPadding + (i * chartWidth / 10);
        ctx.beginPath();
        ctx.moveTo(x, padding);
        ctx.lineTo(x, height - padding);
        ctx.stroke();
      }
      
      // Horizontal grid lines (every 10%)
      for (let i = 0; i <= 10; i++) {
        const y = padding + (i * chartHeight / 10);
        ctx.beginPath();
        ctx.moveTo(leftPadding, y);
        ctx.lineTo(leftPadding + chartWidth, y);
        ctx.stroke();
      }
      
      // Draw axes
      ctx.strokeStyle = '#374151';
      ctx.lineWidth = 2;
      ctx.beginPath();
      ctx.moveTo(leftPadding, padding);
      ctx.lineTo(leftPadding, height - padding);
      ctx.lineTo(leftPadding + chartWidth, height - padding);
      ctx.stroke();
      
      // Draw axis labels
      ctx.fillStyle = '#374151';
      ctx.font = '12px system-ui';
      ctx.textAlign = 'center';
      
      // X-axis labels (0% to 100%)
      for (let i = 0; i <= 10; i++) {
        const x = leftPadding + (i * chartWidth / 10);
        const value = i * 10;
        // Make 0 and 100 bold
        if (value === 0 || value === 100) {
          ctx.font = 'bold 12px system-ui';
        } else {
          ctx.font = '12px system-ui';
        }
        ctx.fillText(`${value}`, x, height - padding + 20);
      }
      
      // Y-axis labels (0% to 100%)
      ctx.textAlign = 'right';
      for (let i = 0; i <= 10; i++) {
        const y = height - padding - (i * chartHeight / 10);
        const value = i * 10;
        // Make 0 and 100 bold
        if (value === 0 || value === 100) {
          ctx.font = 'bold 12px system-ui';
        } else {
          ctx.font = '12px system-ui';
        }
        ctx.fillText(`${value}`, leftPadding - 10, y + 4);
      }
      
      // Axis titles
      ctx.textAlign = 'center';
      ctx.font = '14px system-ui';
      ctx.fillText('Input Level (1-100)', width / 2, height - 10);
      
      ctx.save();
      ctx.translate(15, height / 2);
      ctx.rotate(-Math.PI / 2);
      ctx.fillText('Ink Limit Percentage', 0, 0);
      ctx.restore();
      
      // Draw curves and collect label info
      const labels = [];
      const hasLinearization = (linearizationData && linearizationApplied) || Object.keys(perChannelLinearization).length > 0;
      
      Array.from(elements.rows.children).forEach((row, index) => {
        const channelName = row.querySelector('td span span:nth-child(2)').textContent.trim();
        const endVal = InputValidator.clampEnd(row.querySelector('.end-input').value);
        
        if (endVal === 0) return; // Skip disabled channels
        
        const percent = InputValidator.computePercentFromEnd(endVal);
        const inkColor = INK_COLORS[channelName] || '#000000';
        
        // Generate the 256 values with linearization
        const values = make256(endVal, channelName, true);
        const maxValue = TOTAL; // 64000
        
        // If linearization is applied, first draw a faded linear reference line
        if (hasLinearization) {
          // Generate linear values without linearization for comparison
          const linearValues = make256(endVal, channelName, false);
          
          // Draw faded linear reference line
          ctx.strokeStyle = inkColor;
          ctx.globalAlpha = 0.25; // Fade to 25% opacity
          ctx.lineWidth = 1;
          ctx.setLineDash([2, 2]); // Dotted line
          ctx.beginPath();
          
          for (let i = 0; i < linearValues.length; i++) {
            const x = leftPadding + (i / (linearValues.length - 1)) * chartWidth;
            const valuePercent = (linearValues[i] / maxValue) * 100;
            const y = height - padding - (valuePercent / 100) * chartHeight;
            
            if (i === 0) {
              ctx.moveTo(x, y);
            } else {
              ctx.lineTo(x, y);
            }
          }
          
          ctx.stroke();
          ctx.setLineDash([]); // Reset line dash
          ctx.globalAlpha = 1.0; // Reset opacity
        }
        
        // Draw original curve (before smoothing) if conditions are met
        if (shouldShowOriginal && hasLinearization) {
          // Generate the original curve without smoothing by temporarily storing and overriding smoothing
          const currentSmoothing = elements.smoothingSlider.value;
          elements.smoothingSlider.value = '0';
          const originalValues = make256(endVal, channelName, true);
          elements.smoothingSlider.value = currentSmoothing; // Restore original smoothing
          
          // Draw original curve as gray dashed line
          ctx.strokeStyle = '#9CA3AF'; // Gray-400
          ctx.globalAlpha = 0.8;
          ctx.lineWidth = 1;
          ctx.setLineDash([4, 2]); // Dashed line
          ctx.beginPath();
          
          for (let i = 0; i < originalValues.length; i++) {
            const x = leftPadding + (i / (originalValues.length - 1)) * chartWidth;
            const valuePercent = (originalValues[i] / maxValue) * 100;
            const y = height - padding - (valuePercent / 100) * chartHeight;
            
            if (i === 0) {
              ctx.moveTo(x, y);
            } else {
              ctx.lineTo(x, y);
            }
          }
          
          ctx.stroke();
          ctx.setLineDash([]); // Reset line dash
          ctx.globalAlpha = 1.0; // Reset opacity
        }
        
        // Draw the actual linearized curve
        ctx.strokeStyle = inkColor;
        ctx.lineWidth = 2;
        ctx.beginPath();
        
        // Plot the curve
        for (let i = 0; i < values.length; i++) {
          const x = leftPadding + (i / (values.length - 1)) * chartWidth;
          const valuePercent = (values[i] / maxValue) * 100;
          const y = height - padding - (valuePercent / 100) * chartHeight;
          
          if (i === 0) {
            ctx.moveTo(x, y);
          } else {
            ctx.lineTo(x, y);
          }
        }
        
        ctx.stroke();
        
        // Store label info for later positioning
        const actualEndValue = values[values.length - 1];
        const actualEndPercent = (actualEndValue / maxValue) * 100;
        const endY = height - padding - (actualEndPercent / 100) * chartHeight;
        
        labels.push({
          channelName,
          percent: Math.round(percent),
          inkColor,
          endY
        });
      });
      
      // Draw labels with collision avoidance
      if (labels.length > 0) {
        labels.sort((a, b) => a.endY - b.endY); // Sort by Y position
        
        ctx.font = 'bold 12px system-ui';
        ctx.textAlign = 'left';
        
        const minSpacing = 20; // Minimum spacing between labels
        const endX = leftPadding + chartWidth; // Position labels at the right edge of chart
        
        // Adjust label positions to avoid overlaps
        for (let i = 0; i < labels.length; i++) {
          let labelY = labels[i].endY + 4;
          
          // Check for overlap with previous label
          if (i > 0) {
            const prevLabelY = labels[i-1].adjustedY || (labels[i-1].endY + 4);
            if (labelY - prevLabelY < minSpacing) {
              labelY = prevLabelY + minSpacing;
            }
          }
          
          // Store adjusted position
          labels[i].adjustedY = labelY;
          
          // Draw the label with background for better readability
          const labelText = `${labels[i].channelName} (${labels[i].percent}%)`;
          const textMetrics = ctx.measureText(labelText);
          const textWidth = textMetrics.width;
          const textHeight = 18; // Background height for 12px text with padding
          
          // Draw solid white background
          ctx.fillStyle = 'rgba(255, 255, 255, 1.0)';
          ctx.fillRect(endX, labelY - textHeight + 2, textWidth + 4, textHeight + 2);
          
          // Calculate centered text position within the background
          const textCenterY = labelY - (textHeight / 2) + 2 + (textHeight / 2);
          
          // Draw text shadow first
          ctx.fillStyle = 'rgba(0, 0, 0, 0.3)';
          ctx.fillText(labelText, endX + 3, textCenterY + 1);
          
          // Draw the text
          ctx.fillStyle = labels[i].inkColor;
          ctx.fillText(labelText, endX + 2, textCenterY);
        }
      }
      
      // Animate logo bars when chart is redrawn
      animateLogoBars();
    }

    // Generate filename based on current settings
    function generateFilename() {
      const p = PRINTERS[elements.printerSelect.value];
      // Extract just the printer model (remove "Epson " prefix)
      const printerModel = p.name.replace(/^Epson\s+/, '').replace(/\s+/g, '');
      let parts = [printerModel]; // Start with printer model
      
      // Add active channels with their percentages
      Array.from(elements.rows.children).forEach((tr) => {
        const name = tr.querySelector('td span span:nth-child(2)').textContent.trim();
        const endVal = InputValidator.clampEnd(tr.querySelector('.end-input').value);
        
        if (endVal > 0) {
          const percent = Math.round(InputValidator.computePercentFromEnd(endVal));
          parts.push(name + percent);
        }
      });
      
      // Add CORRECTED suffix if any linearization is applied
      const hasLinearization = (linearizationData && linearizationApplied) || 
                                Object.keys(perChannelLinearization).some(ch => perChannelEnabled[ch]);
      if (hasLinearization) {
        parts.push('CORRECTED');
      }
      
      return parts.join('_');
    }

    // Update filename input with current settings
    function updateFilename() {
      if (!elements.filenameInput.dataset.userEdited) {
        elements.filenameInput.value = generateFilename();
        // Trigger validation styling
        elements.filenameInput.dispatchEvent(new Event('input'));
      }
    }
    function sanitizeFilename(filename) {
      // Remove or replace invalid characters for Windows and Mac
      // Invalid: \ / : * ? " < > |
      return filename
        .replace(/[\\/:*?"<>|]/g, '_')  // Replace invalid chars with underscore
        .replace(/\s+/g, '_')          // Replace spaces with underscores
        .replace(/_{2,}/g, '_')        // Replace multiple underscores with single
        .replace(/^_+|_+$/g, '')       // Trim underscores from start/end
        .substring(0, 200);            // Limit length to 200 chars
    }

    // ---- Linearization utilities ----
    const clamp01 = (x) => Math.max(0, Math.min(1, x));

    // Linearization data storage
    let linearizationData = null;
    let linearizationApplied = false;
    let loadedQuadData = null; // Stores complete curve data from loaded .quad files
    
    // Clear loaded quad data
    function clearLoadedQuadData() {
      loadedQuadData = null;
      if (elements.quadFileInfo) {
        elements.quadFileInfo.classList.add('hidden');
      }
      // Update interpolation controls since loaded data is no longer available
      updateInterpolationControls();
    }
    
    // Check if any linearization is available that would benefit from interpolation
    function hasAnyLinearization() {
      return (linearizationData && linearizationApplied) || 
             Object.keys(perChannelLinearization).length > 0;
      // Note: Loaded .quad data alone doesn't need interpolation since it already has 256 points
    }
    
    // Update interpolation description based on selected method
    function updateInterpolationDescription() {
      const method = elements.curveSmoothingMethod.value;
      const hasLinearization = hasAnyLinearization();
      const hasLoadedQuad = loadedQuadData && loadedQuadData.curves;
      
      if (!hasLinearization && hasLoadedQuad) {
        // Show explanation when disabled due to loaded .quad file
        elements.interpolationDescription.textContent = 'Disabled: Loaded .quad file already contains processed curves';
        elements.interpolationDescription.className = 'text-xs text-gray-500 italic mt-3';
        elements.interpolationDescription.style.display = 'block';
      } else if (!hasLinearization) {
        // Show explanation when disabled due to no linearization
        elements.interpolationDescription.textContent = 'Disabled: no data loaded';
        elements.interpolationDescription.className = 'text-xs text-gray-500 italic mt-3';
        elements.interpolationDescription.style.display = 'block';
      } else {
        // Hide description when enabled (controls are self-explanatory when active)
        elements.interpolationDescription.style.display = 'none';
      }
    }
    
    // Update interpolation controls based on linearization availability
    function updateInterpolationControls() {
      const hasLinearization = hasAnyLinearization();
      elements.curveSmoothingMethod.disabled = !hasLinearization;
      elements.catmullTension.disabled = !hasLinearization;
      elements.smoothingSlider.disabled = !hasLinearization;
      elements.simplificationMethod.disabled = !hasLinearization;
      
      // Update visual styling for disabled state
      if (!hasLinearization) {
        elements.curveSmoothingMethod.className = 'standard-dropdown';
      } else {
        elements.curveSmoothingMethod.className = 'standard-dropdown';
      }
      
      // Show/hide tension control for Catmull-Rom
      const method = elements.curveSmoothingMethod.value;
      const showTension = hasLinearization && method === 'catmull';
      elements.catmullTensionContainer.style.display = showTension ? 'block' : 'none';
      
      // Update smoothing warning visibility
      const smoothingPercent = parseFloat(elements.smoothingSlider.value) || 0;
      const showWarning = hasLinearization && smoothingPercent > 0;
      elements.smoothingWarning.classList.toggle('hidden', !showWarning);
      
      // Update description
      updateInterpolationDescription();
    }
    
    // Get selected simplification method
    function getSelectedSimplificationMethod() {
      return elements.simplificationMethod.value || 'douglas-peucker';
    }
    
    // Per-channel linearization storage
    let perChannelLinearization = {};
    let perChannelEnabled = {};
    let perChannelFilenames = {};
    
    // Channel previous values storage (for restore after enable)
    let channelPreviousValues = {};

    /**
     * Parse a .cube file string as a 1D LUT or route to 3D LUT parser.
     * Returns { domainMin, domainMax, samples } where samples are floats (usually 0..1).
     */
    function parseCube1D(cubeText) {
      const lines = cubeText.split(/\r?\n/);
      let domainMin = 0.0;
      let domainMax = 1.0;
      let declaredSize = null;
      const samples = [];

      // Check for 3D LUT indicators early - route to appropriate parser
      for (const raw of lines) {
        const s = raw.trim();
        if (!s || s.startsWith("#") || /^TITLE/i.test(s)) continue;
        
        // Detect 3D LUT file format and route to 3D parser
        if (/^LUT_3D_SIZE/i.test(s)) {
          return parseCube3D(cubeText);
        }
      }

      for (const raw of lines) {
        const s = raw.trim();
        if (!s || s.startsWith("#") || /^TITLE/i.test(s)) continue;

        if (/^LUT_1D_SIZE/i.test(s)) {
          const m = s.match(/LUT_1D_SIZE\s+(\d+)/i);
          if (m) declaredSize = parseInt(m[1], 10);
          continue;
        }
        if (/^DOMAIN_MIN/i.test(s)) {
          // 1 or 3 numbers; for 1D we take the first
          const parts = s.split(/\s+/);
          if (parts[1] !== undefined) domainMin = parseFloat(parts[1]);
          continue;
        }
        if (/^DOMAIN_MAX/i.test(s)) {
          const parts = s.split(/\s+/);
          if (parts[1] !== undefined) domainMax = parseFloat(parts[1]);
          continue;
        }

        // Numeric row: could be 1‚Äì3 floats. For LUTs, many files still list RGB triplets.
        const nums = s.split(/\s+/).map(Number);
        if (nums.every((v) => Number.isFinite(v)) && nums.length >= 1 && nums.length <= 3) {
          samples.push(nums[0]); // take the first channel for 1D
        }
      }

      // After parsing, check if this looks like 3D LUT data
      if (samples.length > 100) {
        // LUTs with very high point counts may indicate parsing issues
        throw new Error("This file contains an unusually high number of data points. Please verify the file format and try again.");
      }

      if (declaredSize !== null && samples.length >= declaredSize) {
        samples.length = declaredSize;
      }
      if (!Number.isFinite(domainMin) || !Number.isFinite(domainMax) || domainMin === domainMax) {
        domainMin = 0.0; domainMax = 1.0;
      }
      if (!samples.length) {
        throw new Error("No 1D samples found in .cube text.");
      }

      // Apply both horizontal and vertical flips to match printing coordinate system
      // First: horizontal flip (reverse coordinate positions)
      const horizontallyFlipped = samples.map((sample, i) => {
        const inputPos = i / (samples.length - 1); // Current input position (0-1)
        const flippedInputPos = 1.0 - inputPos; // Horizontal flip
        const flippedInputIndex = Math.round(flippedInputPos * (samples.length - 1)); // Convert back to index
        const clampedIndex = Math.max(0, Math.min(samples.length - 1, flippedInputIndex));
        return samples[clampedIndex];
      });
      
      // Second: vertical flip (invert values so 0.0 becomes 1.0, 0.5 becomes 0.5, etc.)
      const flippedSamples = horizontallyFlipped.map(sample => 1.0 - sample);
      
      return { domainMin, domainMax, samples: flippedSamples };
    }

    /**
     * Parse a 3D LUT (.cube) file and extract neutral axis for linearization.
     * Returns { domainMin, domainMax, samples } where samples represent the neutral axis (R=G=B) response.
     */
    function parseCube3D(cubeText) {
      const lines = cubeText.split(/\r?\n/);
      let domainMin = 0.0;
      let domainMax = 1.0;
      let lutSize = null;
      const lutData = [];

      // Parse header information
      for (const raw of lines) {
        const s = raw.trim();
        if (!s || s.startsWith("#") || /^TITLE/i.test(s)) continue;

        if (/^LUT_3D_SIZE/i.test(s)) {
          const m = s.match(/LUT_3D_SIZE\s+(\d+)/i);
          if (m) lutSize = parseInt(m[1], 10);
          continue;
        }
        if (/^DOMAIN_MIN/i.test(s)) {
          const parts = s.split(/\s+/);
          if (parts[1] !== undefined) domainMin = parseFloat(parts[1]);
          continue;
        }
        if (/^DOMAIN_MAX/i.test(s)) {
          const parts = s.split(/\s+/);
          if (parts[1] !== undefined) domainMax = parseFloat(parts[1]);
          continue;
        }

        // Parse RGB data lines
        const parts = s.split(/\s+/);
        if (parts.length === 3) {
          const r = parseFloat(parts[0]);
          const g = parseFloat(parts[1]);
          const b = parseFloat(parts[2]);
          if (!isNaN(r) && !isNaN(g) && !isNaN(b)) {
            lutData.push([r, g, b]);
          }
        }
      }

      if (!lutSize) {
        throw new Error("3D LUT size not found. Expected LUT_3D_SIZE declaration.");
      }

      const expectedDataPoints = lutSize * lutSize * lutSize;
      if (lutData.length !== expectedDataPoints) {
        throw new Error(`3D LUT data mismatch. Expected ${expectedDataPoints} points, found ${lutData.length}.`);
      }

      // Extract neutral axis (diagonal where R=G=B)
      const neutralAxisSamples = [];
      const outputSteps = 256; // Generate 256 samples for consistency with other LUT processing

      for (let i = 0; i < outputSteps; i++) {
        const input = i / (outputSteps - 1); // 0 to 1
        const neutralRGB = [input, input, input]; // R=G=B for neutral gray
        
        // Trilinear interpolation in 3D LUT
        const outputRGB = trilinearInterpolate3D(neutralRGB, lutData, lutSize, domainMin, domainMax);
        
        // Convert RGB output to luminance (simple average for neutral axis)
        const luminance = (outputRGB[0] + outputRGB[1] + outputRGB[2]) / 3;
        neutralAxisSamples.push(luminance);
      }

      // Apply coordinate system transformations to match other LUT processing
      const horizontallyFlipped = neutralAxisSamples.map((sample, i) => {
        const inputPos = i / (neutralAxisSamples.length - 1);
        const flippedInputPos = 1.0 - inputPos;
        const flippedInputIndex = Math.round(flippedInputPos * (neutralAxisSamples.length - 1));
        const clampedIndex = Math.max(0, Math.min(neutralAxisSamples.length - 1, flippedInputIndex));
        return neutralAxisSamples[clampedIndex];
      });
      
      const flippedSamples = horizontallyFlipped.map(sample => 1.0 - sample);
      
      return { 
        domainMin, 
        domainMax, 
        samples: flippedSamples,
        is3DLUT: true,
        lutSize: lutSize,
        originalDataPoints: expectedDataPoints
      };
    }

    /**
     * Trilinear interpolation for 3D LUT sampling
     * @private
     */
    function trilinearInterpolate3D(inputRGB, lutData, lutSize, domainMin, domainMax) {
      const [r, g, b] = inputRGB;
      
      // Normalize input to LUT coordinates (0 to lutSize-1)
      const normalizedR = (r - domainMin) / (domainMax - domainMin);
      const normalizedG = (g - domainMin) / (domainMax - domainMin);
      const normalizedB = (b - domainMin) / (domainMax - domainMin);
      
      const lutR = Math.max(0, Math.min(lutSize - 1, normalizedR * (lutSize - 1)));
      const lutG = Math.max(0, Math.min(lutSize - 1, normalizedG * (lutSize - 1)));
      const lutB = Math.max(0, Math.min(lutSize - 1, normalizedB * (lutSize - 1)));
      
      // Get integer indices and fractional parts
      const r0 = Math.floor(lutR), r1 = Math.min(lutSize - 1, r0 + 1);
      const g0 = Math.floor(lutG), g1 = Math.min(lutSize - 1, g0 + 1);
      const b0 = Math.floor(lutB), b1 = Math.min(lutSize - 1, b0 + 1);
      
      const fr = lutR - r0;
      const fg = lutG - g0;
      const fb = lutB - b0;
      
      // Get the 8 corner values from the LUT cube
      const corners = [
        lutData[r0 * lutSize * lutSize + g0 * lutSize + b0], // (r0,g0,b0)
        lutData[r1 * lutSize * lutSize + g0 * lutSize + b0], // (r1,g0,b0)
        lutData[r0 * lutSize * lutSize + g1 * lutSize + b0], // (r0,g1,b0)
        lutData[r1 * lutSize * lutSize + g1 * lutSize + b0], // (r1,g1,b0)
        lutData[r0 * lutSize * lutSize + g0 * lutSize + b1], // (r0,g0,b1)
        lutData[r1 * lutSize * lutSize + g0 * lutSize + b1], // (r1,g0,b1)
        lutData[r0 * lutSize * lutSize + g1 * lutSize + b1], // (r0,g1,b1)
        lutData[r1 * lutSize * lutSize + g1 * lutSize + b1]  // (r1,g1,b1)
      ];
      
      // Trilinear interpolation
      const result = [0, 0, 0];
      for (let c = 0; c < 3; c++) {
        const c00 = corners[0][c] * (1 - fr) + corners[1][c] * fr;
        const c01 = corners[2][c] * (1 - fr) + corners[3][c] * fr;
        const c10 = corners[4][c] * (1 - fr) + corners[5][c] * fr;
        const c11 = corners[6][c] * (1 - fr) + corners[7][c] * fr;
        
        const c0 = c00 * (1 - fg) + c01 * fg;
        const c1 = c10 * (1 - fg) + c11 * fg;
        
        result[c] = c0 * (1 - fb) + c1 * fb;
      }
      
      return result;
    }

    /**
     * Parse a Color Muse data file (tab-separated format)
     * Expected format:
     * GRAY	LAB_L	LAB_A	LAB_B
     * 0	97.50	0.20	-0.50
     * 5	93.40	0.30	-0.70
     * ...
     * Returns { domainMin: 0, domainMax: 1, samples } where samples are normalized 0..1
     */
    function parseColorMuseData(fileContent, filename) {
      const lines = fileContent.split(/\r?\n/);
      const dataPoints = [];
      let headerFound = false;
      
      for (const line of lines) {
        const trimmed = line.trim();
        
        // Skip empty lines
        if (!trimmed) continue;
        
        // Check for Color Muse header
        if (trimmed.includes('GRAY') && trimmed.includes('LAB_L')) {
          headerFound = true;
          continue;
        }
        
        // Skip other comment lines
        if (trimmed.startsWith('#') || trimmed.startsWith('//')) continue;
        
        // Parse data lines (tab-separated: GRAY LAB_L LAB_A LAB_B)
        const parts = trimmed.split(/\s+/);
        if (parts.length >= 2) {
          const grayPercent = parseFloat(parts[0]);
          const labL = parseFloat(parts[1]);
          
          // Validate the parsed values
          if (!isNaN(grayPercent) && !isNaN(labL) && 
              grayPercent >= 0 && grayPercent <= 100 && 
              labL >= 0 && labL <= 100) {
            dataPoints.push({ input: grayPercent, lab: labL });
          }
        }
      }
      
      if (dataPoints.length < 2) {
        throw new Error("Not enough valid Color Muse data points found. Expected format: GRAY\\tLAB_L\\tLAB_A\\tLAB_B");
      }
      
      // Sort by gray percentage
      dataPoints.sort((a, b) => a.input - b.input);
      
      // Store original data points for smoothing
      const originalDataPoints = [...dataPoints];
      
      // For linearization correction, we need to create a forward correction curve
      // The measured data shows: input% -> actual LAB L*
      // We want: input% -> corrected output% to achieve linear response
      
      // First, normalize L* values to full 0-100 range
      const labValues = dataPoints.map(p => p.lab);
      const minLab = Math.min(...labValues);
      const maxLab = Math.max(...labValues);
      const labRange = maxLab - minLab;
      
      // NEW APPROACH: What if we need to flip the relationship entirely?
      // Coordinate system transformation: Industry standard treats measured L* as target, GRAY% as achieved value
      // Implementation: measured L* defines target, GRAY% defines input mapping
      
      // Convert L* to density-like values (invert since higher L* = lighter = lower density)
      const densityPoints = dataPoints.map(point => ({
        // Target density (inverted from L*): 0% GRAY should be 0 density, 100% GRAY should be 1 density
        targetDensity: point.input / 100,
        // What density we actually got (invert L* so high L* becomes low density)
        actualDensity: labRange > 0 ? 1.0 - ((point.lab - minLab) / labRange) : 0.5
      }));
      
      // Sort by target density
      densityPoints.sort((a, b) => a.targetDensity - b.targetDensity);
      
      console.log('Density mapping:', densityPoints.slice(0, 5)); // Debug first few points
      
      // Create correction curve: for each target density, find what input density produces it
      const samples = [];
      
      for (let i = 0; i < 256; i++) {
        const targetDensity = i / 255; // What density we want (0 = highlight, 1 = shadow)
        let correctedInput = targetDensity; // fallback to linear
        
        // Find what actual input produces this target density
        for (let j = 0; j < densityPoints.length - 1; j++) {
          const d1 = densityPoints[j];
          const d2 = densityPoints[j + 1];
          
          // Check if target falls between these actual density values
          const minActual = Math.min(d1.actualDensity, d2.actualDensity);
          const maxActual = Math.max(d1.actualDensity, d2.actualDensity);
          
          if (targetDensity >= minActual && targetDensity <= maxActual) {
            // Interpolate to find what target density produces this actual density
            const denom = d2.actualDensity - d1.actualDensity;
            if (Math.abs(denom) > 1e-10) {
              const t = (targetDensity - d1.actualDensity) / denom;
              correctedInput = d1.targetDensity + t * (d2.targetDensity - d1.targetDensity);
            }
            break;
          }
        }
        
        // Handle edge cases
        if (targetDensity < Math.min(...densityPoints.map(p => p.actualDensity))) {
          const minPoint = densityPoints.reduce((min, p) => p.actualDensity < min.actualDensity ? p : min);
          correctedInput = minPoint.targetDensity;
        } else if (targetDensity > Math.max(...densityPoints.map(p => p.actualDensity))) {
          const maxPoint = densityPoints.reduce((max, p) => p.actualDensity > max.actualDensity ? p : max);
          correctedInput = maxPoint.targetDensity;
        }
        
        samples.push(correctedInput);
      }
      
      // Dual transformation application: Coordinate system alignment with industry standard
      const flippedSamples = samples.map((sample, i) => {
        const inputPos = i / 255; // Current input position (0-1)
        const flippedInputPos = 1.0 - inputPos; // Horizontal flip
        const flippedInputIndex = Math.round(flippedInputPos * 255); // Convert back to index
        const clampedIndex = Math.max(0, Math.min(255, flippedInputIndex));
        const originalSample = samples[clampedIndex];
        const verticallyFlipped = 1.0 - originalSample; // Vertical flip
        return verticallyFlipped;
      });
      
      // Create normalized input domain (0-1 corresponding to 0%-100%)
      const domainMin = 0.0;
      const domainMax = 1.0;
      
      return {
        domainMin,
        domainMax, 
        samples: flippedSamples,
        originalData: originalDataPoints, // Keep original for reference
        originalSamples: flippedSamples, // Store full-resolution samples
        format: 'LAB Data',
        // Function to generate smoothed control points (not full 256-point curve)
        getSmoothingControlPoints: function(smoothingPercent) {
          // Always return control points to allow interpolation methods to work
          // When smoothing is 0%, use all original data points
          
          // Apply smoothing to original data points while preserving their structure
          let smoothedDataPoints;
          
          if (smoothingPercent === 0) {
            // Use all original data points when no smoothing is applied
            smoothedDataPoints = [...originalDataPoints];
          } else {
            const simplificationMethod = getSelectedSimplificationMethod();
            
            if (simplificationMethod === 'douglas-peucker') {
              // For Douglas-Peucker, create points with both input and LAB values
              const points = originalDataPoints.map(p => ({x: p.input, y: p.lab}));
              const labRange = Math.max(...originalDataPoints.map(p => p.lab)) - Math.min(...originalDataPoints.map(p => p.lab));
              const tolerance = (labRange * 0.01) * (smoothingPercent / 100) * 2;
              const simplified = CurveSimplification._douglasPeuckerRecursive(points, tolerance);
              smoothedDataPoints = simplified.map(p => ({input: p.x, lab: p.y}));
            } else {
              // For uniform sampling, reduce the data points array directly
              const keepRatio = 1.0 - (smoothingPercent / 100);
              const targetCount = Math.max(3, Math.round(originalDataPoints.length * keepRatio));
              const step = (originalDataPoints.length - 1) / (targetCount - 1);
              
              smoothedDataPoints = [];
              for (let i = 0; i < targetCount; i++) {
                const index = Math.round(i * step);
                smoothedDataPoints.push(originalDataPoints[index]);
              }
            }
          }
          
          // Process smoothed data points through transformation pipeline
          const processedLabValues = smoothedDataPoints.map(p => p.lab);
          const minLab = Math.min(...processedLabValues);
          const maxLab = Math.max(...processedLabValues);
          const labRange = maxLab - minLab;
          
          const densityPoints = smoothedDataPoints.map(point => ({
            targetDensity: point.input / 100,
            actualDensity: labRange > 0 ? 1.0 - ((point.lab - minLab) / labRange) : 0.5
          }));
          
          densityPoints.sort((a, b) => a.targetDensity - b.targetDensity);
          
          // Create sparse control points that represent the inverse mapping needed for linearization
          // Each point maps from target density (x) to what actual input density produces it (y)
          const controlPoints = [];
          const controlPointsX = [];
          
          // Process each reduced density point to create control points for interpolation
          for (let i = 0; i < densityPoints.length; i++) {
            const point = densityPoints[i];
            
            // The control points need to represent: for target density X, use input Y
            // This is the inverse of what we measured: input X produced actual density Y
            
            // Apply dual transformation to create printing coordinate system
            const xCoord = 1.0 - point.actualDensity; // Horizontal flip: actual becomes target
            const yValue = 1.0 - point.targetDensity; // Vertical flip: target becomes corrected input
            
            controlPointsX.push(xCoord);
            controlPoints.push(yValue);
          }
          
          // Sort by X coordinate for proper interpolation
          const combined = controlPointsX.map((x, i) => ({x, y: controlPoints[i]}));
          combined.sort((a, b) => a.x - b.x);
          
          return {
            samples: combined.map(p => p.y),
            xCoords: combined.map(p => p.x),
            controlPointCount: combined.length,
            needsDualTransformation: false // Transformation already applied to control points
          };
        }
      };
    }


    /**
     * Detect file type and parse appropriately
     * For text files, pass the file content as string
     */
    async function parseLinearizationFile(fileContentOrFile, filename) {
      const extension = filename.toLowerCase().split('.').pop();
      
      if (extension === 'cube') {
        return parseCube1D(fileContentOrFile);
      } else if (extension === 'txt') {
        // Check if it's Color Muse format by looking for the header
        if (fileContentOrFile.includes('GRAY') && fileContentOrFile.includes('LAB_L')) {
          return parseColorMuseData(fileContentOrFile, filename);
        } else {
          throw new Error('TXT file format not recognized. Expected Color Muse format with GRAY and LAB_L columns.');
        }
      } else {
        throw new Error(`Unsupported file format: ${extension}. Use .cube or .txt files.`);
      }
    }

    /**
     * Natural cubic spline interpolation
     * @param {number[]} x - input points (typically 0, 1, 2, ..., n-1)
     * @param {number[]} y - output values at each point
     * @returns {function} interpolation function that takes a value and returns interpolated result
     */
    function createCubicSpline(x, y) {
      const n = x.length;
      if (n < 2) return (t) => y[0] || 0;
      
      // Use clamped cubic spline with estimated end derivatives for more curvature
      const h = new Array(n - 1);
      const alpha = new Array(n);
      const l = new Array(n);
      const mu = new Array(n);
      const z = new Array(n);
      const c = new Array(n);
      const b = new Array(n);
      const d = new Array(n);
      
      // Step 1: Calculate h
      for (let i = 0; i < n - 1; i++) {
        h[i] = x[i + 1] - x[i];
      }
      
      // Step 2: Set up alpha with clamped boundary conditions
      // Estimate end derivatives to allow more curvature
      const firstDerivative = (y[1] - y[0]) / h[0];
      const lastDerivative = (y[n-1] - y[n-2]) / h[n-2];
      
      alpha[0] = 3 * ((y[1] - y[0]) / h[0] - firstDerivative);
      alpha[n-1] = 3 * (lastDerivative - (y[n-1] - y[n-2]) / h[n-2]);
      
      for (let i = 1; i < n - 1; i++) {
        alpha[i] = (3 / h[i]) * (y[i + 1] - y[i]) - (3 / h[i - 1]) * (y[i] - y[i - 1]);
      }
      
      // Step 3: Solve tridiagonal system with clamped conditions
      l[0] = 2 * h[0];
      mu[0] = 0.5;
      z[0] = alpha[0] / l[0];
      
      for (let i = 1; i < n - 1; i++) {
        l[i] = 2 * (x[i + 1] - x[i - 1]) - h[i - 1] * mu[i - 1];
        mu[i] = h[i] / l[i];
        z[i] = (alpha[i] - h[i - 1] * z[i - 1]) / l[i];
      }
      
      l[n - 1] = h[n - 2] * (2 - mu[n - 2]);
      z[n - 1] = (alpha[n - 1] - h[n - 2] * z[n - 2]) / l[n - 1];
      c[n - 1] = z[n - 1];
      
      // Step 4: Back substitution
      for (let j = n - 2; j >= 0; j--) {
        c[j] = z[j] - mu[j] * c[j + 1];
        b[j] = (y[j + 1] - y[j]) / h[j] - h[j] * (c[j + 1] + 2 * c[j]) / 3;
        d[j] = (c[j + 1] - c[j]) / (3 * h[j]);
      }
      
      // Return interpolation function
      return (t) => {
        if (t <= x[0]) return y[0];
        if (t >= x[n - 1]) return y[n - 1];
        
        // Find interval
        let i = 0;
        while (i < n - 1 && x[i + 1] < t) i++;
        
        // Evaluate cubic polynomial - clamped cubic spline interpolation
        const dt = t - x[i];
        return y[i] + b[i] * dt + c[i] * dt * dt + d[i] * dt * dt * dt;
      };
    }

    /**
     * Catmull-Rom spline interpolation
     * @param {number[]} x - input points (typically 0, 1, 2, ..., n-1)
     * @param {number[]} y - output values at each point
     * @returns {function} interpolation function that takes a value and returns interpolated result
     */
    function createCatmullRomSpline(x, y, tension = 0.5) {
      const n = x.length;
      if (n < 2) return (t) => y[0] || 0;
      
      return (t) => {
        if (t <= x[0]) return y[0];
        if (t >= x[n - 1]) return y[n - 1];
        
        // Find interval
        let i = 0;
        while (i < n - 1 && x[i + 1] < t) i++;
        
        // Get the four control points (with boundary handling)
        const p0 = y[Math.max(0, i - 1)];
        const p1 = y[i];
        const p2 = y[Math.min(n - 1, i + 1)];
        const p3 = y[Math.min(n - 1, i + 2)];
        
        // Normalize t to 0-1 within the segment
        const t_norm = (t - x[i]) / (x[i + 1] - x[i]);
        const t2 = t_norm * t_norm;
        const t3 = t2 * t_norm;
        
        // Parameterized Catmull-Rom basis functions with tension control
        // tension = 0.0: very tight (close to linear)
        // tension = 0.5: standard Catmull-Rom
        // tension = 1.0: very loose/curvy
        const q0 = -tension * t3 + 2 * tension * t2 - tension * t_norm;
        const q1 = (2 - tension) * t3 + (tension - 3) * t2 + 1;
        const q2 = (tension - 2) * t3 + (3 - 2 * tension) * t2 + tension * t_norm;
        const q3 = tension * t3 - tension * t2;
        
        // Catmull-Rom interpolation with adjustable tension
        return p0 * q0 + p1 * q1 + p2 * q2 + p3 * q3;
      };
    }

    /**
     * Bezier curve interpolation using cubic Bezier segments
     * @param {number[]} x - input points (typically 0, 1, 2, ..., n-1)
     * @param {number[]} y - output values at each point
     * @returns {function} interpolation function that takes a value and returns interpolated result
     */
    function createBezierSpline(x, y, intensity = 0.5) {
      const n = x.length;
      if (n < 2) return (t) => y[0] || 0;
      
      // Calculate control points for smooth Bezier curves
      const segments = [];
      
      for (let i = 0; i < n - 1; i++) {
        const p0 = { x: x[i], y: y[i] };
        const p3 = { x: x[i + 1], y: y[i + 1] };
        
        // Calculate control points based on neighboring points
        let p1, p2;
        
        if (i === 0) {
          // First segment - use forward difference
          const slope = (y[i + 1] - y[i]) / (x[i + 1] - x[i]);
          const dist = (x[i + 1] - x[i]) / 3;
          p1 = { x: x[i] + dist, y: y[i] + slope * dist };
          p2 = { x: x[i + 1] - dist, y: y[i + 1] - slope * dist };
        } else if (i === n - 2) {
          // Last segment - use backward difference
          const slope = (y[i + 1] - y[i]) / (x[i + 1] - x[i]);
          const dist = (x[i + 1] - x[i]) / 3;
          p1 = { x: x[i] + dist, y: y[i] + slope * dist };
          p2 = { x: x[i + 1] - dist, y: y[i + 1] - slope * dist };
        } else {
          // Middle segments - use centered differences for smooth transitions
          const prevSlope = (y[i] - y[i - 1]) / (x[i] - x[i - 1]);
          const nextSlope = (y[i + 2] - y[i + 1]) / (x[i + 2] - x[i + 1]);
          const currentSlope = (y[i + 1] - y[i]) / (x[i + 1] - x[i]);
          
          // Smooth the slopes for continuity
          const smoothSlope1 = (prevSlope + currentSlope) / 2;
          const smoothSlope2 = (currentSlope + nextSlope) / 2;
          
          const dist = (x[i + 1] - x[i]) / 3;
          p1 = { x: x[i] + dist, y: y[i] + smoothSlope1 * dist };
          p2 = { x: x[i + 1] - dist, y: y[i + 1] - smoothSlope2 * dist };
        }
        
        segments.push({ p0, p1, p2, p3 });
      }
      
      return (t) => {
        if (t <= x[0]) return y[0];
        if (t >= x[n - 1]) return y[n - 1];
        
        // Find the segment
        let segmentIndex = 0;
        while (segmentIndex < segments.length - 1 && x[segmentIndex + 1] < t) {
          segmentIndex++;
        }
        
        const segment = segments[segmentIndex];
        
        // Normalize t within the segment (0 to 1)
        const segmentT = (t - segment.p0.x) / (segment.p3.x - segment.p0.x);
        
        // Cubic Bezier formula: B(t) = (1-t)¬≥P‚ÇÄ + 3(1-t)¬≤tP‚ÇÅ + 3(1-t)t¬≤P‚ÇÇ + t¬≥P‚ÇÉ
        const u = 1 - segmentT;
        const tt = segmentT * segmentT;
        const uu = u * u;
        const uuu = uu * u;
        const ttt = tt * segmentT;
        
        const interpolated = uuu * segment.p0.y +
               3 * uu * segmentT * segment.p1.y +
               3 * u * tt * segment.p2.y +
               ttt * segment.p3.y;
        
        // Blend between linear and interpolated based on intensity
        const linear = segment.p0.y + (segment.p3.y - segment.p0.y) * segmentT;
        return linear + intensity * (interpolated - linear);
      };
    }

    /**
     * PCHIP (Piecewise Cubic Hermite Interpolating Polynomial) - Monotonic cubic spline
     * @param {number[]} x - input points (typically 0, 1, 2, ..., n-1)
     * @param {number[]} y - output values at each point
     * @returns {function} interpolation function that takes a value and returns interpolated result
     */
    function createPCHIPSpline(x, y) {
      const n = x.length;
      if (n < 2) return (t) => y[0] || 0;
      
      // Calculate slopes (derivatives) at each point
      const slopes = new Array(n);
      const h = new Array(n - 1);
      const delta = new Array(n - 1);
      
      // Calculate intervals and finite differences
      for (let i = 0; i < n - 1; i++) {
        h[i] = x[i + 1] - x[i];
        delta[i] = (y[i + 1] - y[i]) / h[i];
      }
      
      // Calculate slopes using PCHIP method
      slopes[0] = delta[0]; // First point - use forward difference
      slopes[n - 1] = delta[n - 2]; // Last point - use backward difference
      
      for (let i = 1; i < n - 1; i++) {
        // Interior points - use monotonic slope calculation
        if (delta[i - 1] * delta[i] <= 0) {
          // Data changes direction - use zero slope to avoid overshooting
          slopes[i] = 0;
        } else {
          // Data is monotonic - use weighted harmonic mean for smooth monotonic interpolation
          const w1 = 2 * h[i] + h[i - 1];
          const w2 = h[i] + 2 * h[i - 1];
          slopes[i] = (w1 + w2) / (w1 / delta[i - 1] + w2 / delta[i]);
        }
      }
      
      return (t) => {
        if (t <= x[0]) return y[0];
        if (t >= x[n - 1]) return y[n - 1];
        
        // Find interval
        let i = 0;
        while (i < n - 1 && x[i + 1] < t) i++;
        
        // Normalize t within the interval
        const dt = t - x[i];
        const h_i = h[i];
        const t_norm = dt / h_i;
        
        // Hermite basis functions
        const h00 = 2 * t_norm * t_norm * t_norm - 3 * t_norm * t_norm + 1;
        const h10 = t_norm * t_norm * t_norm - 2 * t_norm * t_norm + t_norm;
        const h01 = -2 * t_norm * t_norm * t_norm + 3 * t_norm * t_norm;
        const h11 = t_norm * t_norm * t_norm - t_norm * t_norm;
        
        // PCHIP interpolation formula
        return y[i] * h00 + h_i * slopes[i] * h10 + y[i + 1] * h01 + h_i * slopes[i + 1] * h11;
      };
    }

    /**
     * Curve simplification algorithms for data point reduction
     */
    const CurveSimplification = {
      /**
       * Uniform sampling reduction - reduces points while maintaining even distribution
       * @param {number[]} samples - Original sample array
       * @param {number} reductionPercent - Percentage of points to remove (0-90)
       * @returns {number[]} Reduced sample array
       */
      uniformSampling: function(samples, reductionPercent) {
        if (reductionPercent === 0 || samples.length <= 3) return samples;
        
        const keepRatio = 1.0 - (reductionPercent / 100);
        const targetCount = Math.max(3, Math.round(samples.length * keepRatio));
        const step = (samples.length - 1) / (targetCount - 1);
        
        const reducedSamples = [];
        for (let i = 0; i < targetCount; i++) {
          const index = Math.round(i * step);
          reducedSamples.push(samples[index]);
        }
        
        return reducedSamples;
      },
      
      /**
       * Douglas-Peucker algorithm for shape-preserving curve simplification
       * @param {number[]} samples - Original sample array  
       * @param {number} reductionPercent - Percentage of points to remove (0-90)
       * @returns {number[]} Reduced sample array
       */
      douglasPeucker: function(samples, reductionPercent) {
        if (reductionPercent === 0 || samples.length <= 3) return samples;
        
        // Convert samples to points with x,y coordinates
        const points = samples.map((y, x) => ({x, y}));
        
        // Calculate tolerance based on reduction percentage and data range
        const yMin = Math.min(...samples);
        const yMax = Math.max(...samples);
        const range = yMax - yMin;
        const baseTolerance = range * 0.01; // 1% of range as base
        const tolerance = baseTolerance * (reductionPercent / 100) * 2; // Scale with reduction
        
        // Apply Douglas-Peucker recursively
        const simplified = this._douglasPeuckerRecursive(points, tolerance);
        
        // Ensure we have at least 3 points
        if (simplified.length < 3) {
          return this.uniformSampling(samples, reductionPercent);
        }
        
        return simplified.map(point => point.y);
      },
      
      /**
       * Recursive Douglas-Peucker implementation
       * @private
       */
      _douglasPeuckerRecursive: function(points, tolerance) {
        if (points.length <= 2) return points;
        
        const first = points[0];
        const last = points[points.length - 1];
        
        // Find point with maximum distance from line segment
        let maxDistance = 0;
        let maxIndex = 0;
        
        for (let i = 1; i < points.length - 1; i++) {
          const distance = this._pointToLineDistance(points[i], first, last);
          if (distance > maxDistance) {
            maxDistance = distance;
            maxIndex = i;
          }
        }
        
        // If max distance is greater than tolerance, recursively simplify
        if (maxDistance > tolerance) {
          const left = this._douglasPeuckerRecursive(points.slice(0, maxIndex + 1), tolerance);
          const right = this._douglasPeuckerRecursive(points.slice(maxIndex), tolerance);
          
          // Merge results, avoiding duplicate middle point
          return left.slice(0, -1).concat(right);
        } else {
          // All points are within tolerance, return only endpoints
          return [first, last];
        }
      },
      
      /**
       * Calculate perpendicular distance from point to line segment
       * @private
       */
      _pointToLineDistance: function(point, lineStart, lineEnd) {
        const A = lineEnd.x - lineStart.x;
        const B = lineEnd.y - lineStart.y;
        const C = point.x - lineStart.x;
        const D = point.y - lineStart.y;
        
        const dot = A * C + B * D;
        const lenSq = A * A + B * B;
        
        if (lenSq === 0) return Math.sqrt(C * C + D * D);
        
        const param = dot / lenSq;
        let closestX, closestY;
        
        if (param < 0) {
          closestX = lineStart.x;
          closestY = lineStart.y;
        } else if (param > 1) {
          closestX = lineEnd.x;
          closestY = lineEnd.y;
        } else {
          closestX = lineStart.x + param * A;
          closestY = lineStart.y + param * B;
        }
        
        const dx = point.x - closestX;
        const dy = point.y - closestY;
        return Math.sqrt(dx * dx + dy * dy);
      },
      
      /**
       * Calculate tolerance for Douglas-Peucker based on reduction percentage and data range
       * @private
       */
      _calculateTolerance: function(samples, reductionPercent) {
        const yMin = Math.min(...samples);
        const yMax = Math.max(...samples);
        const range = yMax - yMin;
        const baseTolerance = range * 0.01; // 1% of range as base
        return baseTolerance * (reductionPercent / 100) * 2; // Scale with reduction
      },

      /**
       * Smoothing splines data reduction with automatic lambda selection
       * @param {number[]} samples - Original sample array
       * @param {number} reductionPercent - Percentage of points to remove (0-90)
       * @returns {number[]} Smoothed and reduced sample array
       */
      smoothingSplines: function(samples, reductionPercent) {
        if (reductionPercent === 0 || samples.length <= 3) return samples;
        
        const n = samples.length;
        const keepRatio = 1.0 - (reductionPercent / 100);
        const targetCount = Math.max(3, Math.round(n * keepRatio));
        
        // Create input points (x values are indices normalized to 0-1)
        const x = [];
        const y = [];
        for (let i = 0; i < n; i++) {
          x.push(i / (n - 1));
          y.push(samples[i]);
        }
        
        // Calculate smoothing parameter lambda based on reduction percentage
        // Higher reduction = more smoothing
        const dataRange = Math.max(...y) - Math.min(...y);
        const lambda = Math.pow(reductionPercent / 100, 2) * dataRange * 0.1;
        
        // Build smoothing spline system
        const splineCoefficients = this._buildSmoothingSpline(x, y, lambda);
        
        // Sample the smooth spline at target points
        const reducedSamples = [];
        for (let i = 0; i < targetCount; i++) {
          const t = i / (targetCount - 1);
          const value = this._evaluateSmoothingSpline(splineCoefficients, x, y, t);
          reducedSamples.push(value);
        }
        
        return reducedSamples;
      },

      /**
       * Build smoothing spline coefficients using penalized least squares
       * @private
       */
      _buildSmoothingSpline: function(x, y, lambda) {
        const n = x.length;
        if (n < 4) return { x, y, c: new Array(n).fill(0) };
        
        // For simplicity, use natural cubic spline with roughness penalty
        // This is a simplified implementation focused on data reduction
        const h = [];
        for (let i = 0; i < n - 1; i++) {
          h[i] = x[i + 1] - x[i];
        }
        
        // Build tridiagonal system for natural spline with smoothing
        const A = new Array(n).fill(null).map(() => new Array(n).fill(0));
        const b = new Array(n).fill(0);
        
        // Natural spline boundary conditions with smoothing penalty
        A[0][0] = 1 + lambda;
        A[n-1][n-1] = 1 + lambda;
        b[0] = y[0];
        b[n-1] = y[n-1];
        
        // Interior equations with roughness penalty
        for (let i = 1; i < n - 1; i++) {
          const hi_1 = h[i-1];
          const hi = h[i];
          
          // Data fidelity term
          A[i][i] = 1;
          b[i] = y[i];
          
          // Add smoothing penalty (simplified second derivative penalty)
          if (lambda > 0) {
            A[i][i] += lambda * (2 / (hi_1 + hi));
            if (i > 1) A[i][i-1] = -lambda / (hi_1 + hi);
            if (i < n - 2) A[i][i+1] = -lambda / (hi_1 + hi);
          }
        }
        
        // Solve system using Gaussian elimination
        const c = this._solveTridiagonal(A, b);
        
        return { x, y, c };
      },

      /**
       * Evaluate smoothing spline at parameter t
       * @private
       */
      _evaluateSmoothingSpline: function(spline, x, y, t) {
        const { x: sx, y: sy, c } = spline;
        const n = sx.length;
        
        // Clamp t to valid range
        t = Math.max(0, Math.min(1, t));
        
        // Find interval
        let i = 0;
        while (i < n - 1 && sx[i + 1] < t) i++;
        if (i >= n - 1) return sy[n - 1];
        
        // Linear interpolation with spline smoothing
        const h = sx[i + 1] - sx[i];
        const dt = t - sx[i];
        const ratio = h > 0 ? dt / h : 0;
        
        // Hermite interpolation with smoothing coefficient
        const y0 = sy[i];
        const y1 = sy[i + 1];
        const c0 = c[i];
        const c1 = c[i + 1];
        
        // Cubic Hermite interpolation
        const t2 = ratio * ratio;
        const t3 = t2 * ratio;
        
        const h00 = 2*t3 - 3*t2 + 1;  // (1+2t)(1-t)^2
        const h10 = t3 - 2*t2 + ratio; // t(1-t)^2
        const h01 = -2*t3 + 3*t2;      // t^2(3-2t)
        const h11 = t3 - t2;           // t^2(t-1)
        
        return h00 * y0 + h10 * h * c0 + h01 * y1 + h11 * h * c1;
      },

      /**
       * Solve tridiagonal system using simplified Gaussian elimination
       * @private
       */
      _solveTridiagonal: function(A, b) {
        const n = A.length;
        const x = new Array(n).fill(0);
        
        // Simple Gaussian elimination for small systems
        // Forward elimination
        for (let i = 0; i < n - 1; i++) {
          for (let j = i + 1; j < n; j++) {
            if (Math.abs(A[i][i]) < 1e-12) continue;
            const factor = A[j][i] / A[i][i];
            for (let k = i; k < n; k++) {
              A[j][k] -= factor * A[i][k];
            }
            b[j] -= factor * b[i];
          }
        }
        
        // Back substitution
        for (let i = n - 1; i >= 0; i--) {
          x[i] = b[i];
          for (let j = i + 1; j < n; j++) {
            x[i] -= A[i][j] * x[j];
          }
          if (Math.abs(A[i][i]) > 1e-12) {
            x[i] /= A[i][i];
          }
        }
        
        return x;
      },

      /**
       * Visvalingam-Whyatt algorithm for area-based curve simplification
       * @param {number[]} samples - Original sample array
       * @param {number} reductionPercent - Percentage of points to remove (0-90)
       * @returns {number[]} Reduced sample array
       */
      visvalingamWhyatt: function(samples, reductionPercent) {
        if (reductionPercent === 0 || samples.length <= 3) return samples;
        
        // Convert samples to points with x,y coordinates
        const points = samples.map((y, x) => ({x, y, originalIndex: x}));
        
        // Calculate target number of points to keep
        const keepRatio = 1.0 - (reductionPercent / 100);
        const targetCount = Math.max(3, Math.round(samples.length * keepRatio));
        const pointsToRemove = points.length - targetCount;
        
        if (pointsToRemove <= 0) return samples;
        
        // Calculate initial areas for all interior points
        const areas = new Array(points.length);
        for (let i = 1; i < points.length - 1; i++) {
          areas[i] = this._calculateTriangleArea(points[i-1], points[i], points[i+1]);
        }
        
        // Create a list of removable points with their areas
        const removablePoints = [];
        for (let i = 1; i < points.length - 1; i++) {
          removablePoints.push({index: i, area: areas[i]});
        }
        
        // Remove points iteratively
        let removedCount = 0;
        const removed = new Set();
        
        while (removedCount < pointsToRemove && removablePoints.length > 0) {
          // Find point with minimum area
          let minAreaIndex = 0;
          let minArea = Infinity;
          
          for (let i = 0; i < removablePoints.length; i++) {
            const point = removablePoints[i];
            if (!removed.has(point.index) && point.area < minArea) {
              minArea = point.area;
              minAreaIndex = i;
            }
          }
          
          if (minAreaIndex === -1) break;
          
          const pointToRemove = removablePoints[minAreaIndex];
          removed.add(pointToRemove.index);
          removedCount++;
          
          // Update areas for neighboring points
          const leftNeighbor = this._findLeftNeighbor(pointToRemove.index, removed);
          const rightNeighbor = this._findRightNeighbor(pointToRemove.index, removed, points.length);
          
          // Recalculate areas for affected neighbors
          if (leftNeighbor !== -1 && leftNeighbor > 0) {
            const leftLeftNeighbor = this._findLeftNeighbor(leftNeighbor, removed);
            if (leftLeftNeighbor !== -1) {
              const newArea = this._calculateTriangleArea(
                points[leftLeftNeighbor], 
                points[leftNeighbor], 
                points[rightNeighbor]
              );
              // Update the area in removablePoints
              for (let i = 0; i < removablePoints.length; i++) {
                if (removablePoints[i].index === leftNeighbor) {
                  removablePoints[i].area = newArea;
                  break;
                }
              }
            }
          }
          
          if (rightNeighbor !== -1 && rightNeighbor < points.length - 1) {
            const rightRightNeighbor = this._findRightNeighbor(rightNeighbor, removed, points.length);
            if (rightRightNeighbor !== -1) {
              const newArea = this._calculateTriangleArea(
                points[leftNeighbor], 
                points[rightNeighbor], 
                points[rightRightNeighbor]
              );
              // Update the area in removablePoints
              for (let i = 0; i < removablePoints.length; i++) {
                if (removablePoints[i].index === rightNeighbor) {
                  removablePoints[i].area = newArea;
                  break;
                }
              }
            }
          }
        }
        
        // Build result array with remaining points
        const result = [];
        for (let i = 0; i < points.length; i++) {
          if (!removed.has(i)) {
            result.push(points[i].y);
          }
        }
        
        return result;
      },
      
      /**
       * Calculate triangle area using the shoelace formula
       * @private
       */
      _calculateTriangleArea: function(p1, p2, p3) {
        return Math.abs((p1.x - p3.x) * (p2.y - p1.y) - (p1.x - p2.x) * (p3.y - p1.y)) / 2;
      },
      
      /**
       * Find the nearest left neighbor that hasn't been removed
       * @private
       */
      _findLeftNeighbor: function(index, removed) {
        for (let i = index - 1; i >= 0; i--) {
          if (!removed.has(i)) return i;
        }
        return -1;
      },
      
      /**
       * Find the nearest right neighbor that hasn't been removed
       * @private
       */
      _findRightNeighbor: function(index, removed, length) {
        for (let i = index + 1; i < length; i++) {
          if (!removed.has(i)) return i;
        }
        return -1;
      },

      /**
       * Apply smoothing reduction using current algorithm
       * @param {number[]} samples - Original sample array
       * @param {number} reductionPercent - Percentage of points to remove (0-90)
       * @param {string} algorithm - 'uniform', 'douglas-peucker', 'smoothing-splines', or 'visvalingam-whyatt'
       * @returns {number[]} Reduced sample array
       */
      applySmoothingReduction: function(samples, reductionPercent, algorithm = 'douglas-peucker') {
        if (reductionPercent === 0) return samples;
        
        switch (algorithm) {
          case 'douglas-peucker':
            return this.douglasPeucker(samples, reductionPercent);
          case 'smoothing-splines':
            return this.smoothingSplines(samples, reductionPercent);
          case 'visvalingam-whyatt':
            return this.visvalingamWhyatt(samples, reductionPercent);
          case 'uniform':
          default:
            return this.uniformSampling(samples, reductionPercent);
        }
      }
    };

    /**
     * Apply a LUT to a list of integers using linear, cubic spline, Catmull-Rom, Bezier, or PCHIP interpolation.
     * Preserves the endpoint values - always starts at 0 and ends at the original max value.
     * @param {number[]} values - input integers in [0..maxValue]
     * @param {number[]} lut - samples (floats), typically 0..1
     * @param {number} domainMin - LUT input domain min (typically 0)
     * @param {number} domainMax - LUT input domain max (typically 1)
     * @param {number} maxValue - the maximum value from the original linear ramp
     * @param {string} interpolationType - 'cubic', 'catmull', or 'linear'
     * @returns {number[]} adjusted integer outputs with preserved endpoints
     */
    function apply1DLUT(values, lutOrData, domainMin = 0, domainMax = 1, maxValue = 64000, interpolationType = 'cubic', smoothingPercent = 0) {
      // Handle both direct samples array and linearization data object
      let processedLUT, lutX, needsDualTransformation = false;
      
      if (Array.isArray(lutOrData)) {
        // Direct samples array
        if (smoothingPercent > 0) {
          // For smoothing, we need to preserve the relationship between X positions and Y values
          const originalLength = lutOrData.length;
          const simplificationMethod = getSelectedSimplificationMethod();
          
          if (simplificationMethod === 'douglas-peucker') {
            // Douglas-Peucker preserves important points, so we need to track their original positions
            const points = lutOrData.map((y, x) => ({x, y}));
            const simplified = CurveSimplification._douglasPeuckerRecursive(
              points, 
              CurveSimplification._calculateTolerance(lutOrData, smoothingPercent)
            );
            
            processedLUT = simplified.map(p => p.y);
            
            // For interpolated LAB data (256 points), X coordinates should be evenly spaced
            // For original .cube data, preserve the actual point positions
            if (originalLength === 256 && domainMin === 0 && domainMax === 1) {
              // This is likely interpolated LAB data - use evenly spaced coordinates
              const K = simplified.length;
              lutX = new Array(K);
              for (let i = 0; i < K; i++) {
                lutX[i] = domainMin + (i / (K - 1)) * (domainMax - domainMin);
              }
            } else {
              // This is likely original .cube data - preserve selected point positions
              lutX = simplified.map(p => domainMin + (p.x / (originalLength - 1)) * (domainMax - domainMin));
            }
          } else {
            // Uniform sampling maintains even spacing
            processedLUT = CurveSimplification.applySmoothingReduction(lutOrData, smoothingPercent, simplificationMethod);
            const K = processedLUT.length;
            lutX = new Array(K);
            for (let i = 0; i < K; i++) {
              lutX[i] = domainMin + (i / (K - 1)) * (domainMax - domainMin);
            }
          }
        } else {
          processedLUT = lutOrData;
          const K = processedLUT.length;
          lutX = new Array(K);
          for (let i = 0; i < K; i++) {
            lutX[i] = domainMin + (i / (K - 1)) * (domainMax - domainMin);
          }
        }
      } else if (lutOrData && typeof lutOrData === 'object' && lutOrData.getSmoothingControlPoints) {
        // Linearization data object with smoothing method
        const controlPoints = lutOrData.getSmoothingControlPoints(smoothingPercent);
        if (controlPoints) {
          // Use sparse control points for interpolation
          processedLUT = controlPoints.samples;
          lutX = controlPoints.xCoords;
          needsDualTransformation = controlPoints.needsDualTransformation || false;
        } else {
          // Use original full-resolution samples (no smoothing)
          processedLUT = lutOrData.originalSamples || lutOrData.samples;
          const K = processedLUT.length;
          lutX = new Array(K);
          for (let i = 0; i < K; i++) {
            lutX[i] = domainMin + (i / (K - 1)) * (domainMax - domainMin);
          }
        }
      } else if (lutOrData && lutOrData.samples) {
        // Linearization data object without smoothing method
        processedLUT = smoothingPercent > 0 ? CurveSimplification.applySmoothingReduction(lutOrData.samples, smoothingPercent, getSelectedSimplificationMethod()) : lutOrData.samples;
        const K = processedLUT.length;
        lutX = new Array(K);
        for (let i = 0; i < K; i++) {
          lutX[i] = domainMin + (i / (K - 1)) * (domainMax - domainMin);
        }
      } else {
        // Fallback
        processedLUT = lutOrData;
        const K = processedLUT.length;
        lutX = new Array(K);
        for (let i = 0; i < K; i++) {
          lutX[i] = domainMin + (i / (K - 1)) * (domainMax - domainMin);
        }
      }
      
      const K = processedLUT.length;
      if (K < 2) return values; // Not enough points for interpolation
      
      // Ensure LUT starts at 0 and we know the end value
      const lutStart = processedLUT[0];
      const lutEnd = processedLUT[K - 1];
      
      let interpolationFunction;
      
      if (interpolationType === 'cubic') {
        // Cubic spline interpolation for smoothest curves - pure interpolation
        interpolationFunction = createCubicSpline(lutX, processedLUT);
      } else if (interpolationType === 'catmull') {
        // Catmull-Rom spline interpolation - passes through control points like GIMP
        const tension = elements.catmullTension.value / 100; // Convert 0-100 to 0-1
        interpolationFunction = createCatmullRomSpline(lutX, processedLUT, tension);
      } else if (interpolationType === 'pchip') {
        // PCHIP interpolation for monotonic, shape-preserving curves
        interpolationFunction = createPCHIPSpline(lutX, processedLUT);
      } else {
        // Linear interpolation for exact point-to-point behavior
        interpolationFunction = (t) => {
          // Handle edge cases
          if (t <= lutX[0]) return processedLUT[0];
          if (t >= lutX[K - 1]) return processedLUT[K - 1];
          
          // Find the correct interval in the potentially non-evenly spaced lutX array
          let i0 = 0;
          for (let i = 0; i < K - 1; i++) {
            if (t >= lutX[i] && t <= lutX[i + 1]) {
              i0 = i;
              break;
            }
          }
          
          const i1 = Math.min(i0 + 1, K - 1);
          const x0 = lutX[i0];
          const x1 = lutX[i1];
          const y0 = processedLUT[i0];
          const y1 = processedLUT[i1];
          
          // Linear interpolation between the two points
          if (x1 === x0) return y0; // Avoid division by zero
          const a = (t - x0) / (x1 - x0);
          return (1 - a) * y0 + a * y1;
        };
      }
      
      const result = values.map((v, index) => {
        // Forward mapping implementation: Input value ‚Üí LUT output transformation
        const t = (v / maxValue) * (domainMax - domainMin) + domainMin;
        const lutValue = interpolationFunction(t);
        
        // Scale LUT value directly to maxValue range
        return Math.round(clamp01(lutValue) * maxValue);
      });
      
      // Apply dual transformation if needed (for LAB data with smoothing)
      if (needsDualTransformation) {
        // Convert result back to 0-1 range for transformation
        const normalizedResult = result.map(val => val / maxValue);
        
        // Apply same dual transformation as parseColorMuseData (lines 1571-1579)
        const flippedSamples = normalizedResult.map((sample, i) => {
          const inputPos = i / (normalizedResult.length - 1); // Current input position (0-1)
          const flippedInputPos = 1.0 - inputPos; // Horizontal flip
          const flippedInputIndex = Math.round(flippedInputPos * (normalizedResult.length - 1)); // Convert back to index
          const clampedIndex = Math.max(0, Math.min(normalizedResult.length - 1, flippedInputIndex));
          const originalSample = normalizedResult[clampedIndex];
          const verticallyFlipped = 1.0 - originalSample; // Vertical flip
          return verticallyFlipped;
        });
        
        // Convert back to original scale
        return flippedSamples.map(val => Math.round(clamp01(val) * maxValue));
      }
      
      return result;
    }

    const debouncedPreviewUpdate = debounce(updatePreview, 300);

    // Optimized 256 value generation with optional linearization
    function make256(endValue, channelName, applyLinearization = false) {
      if (endValue === 0) return new Array(N).fill(0);
      
      let arr;
      
      // Step 1: Start with base curve (loaded data or linear ramp)
      if (loadedQuadData && loadedQuadData.curves && loadedQuadData.curves[channelName]) {
        // Use loaded curve data as the starting point
        const loadedCurve = loadedQuadData.curves[channelName];
        const originalEndValue = loadedCurve[255]; // Original final value
        
        if (originalEndValue === 0) {
          return new Array(N).fill(0); // Handle edge case
        }
        
        // Scale the loaded curve to the new end value
        const scaleFactor = endValue / originalEndValue;
        arr = loadedCurve.map(value => Math.round(value * scaleFactor));
      } else {
        // Generate linear ramp as base
        arr = new Array(N);
        const step = endValue / DENOM;
        
        for (let i = 0; i < N; i++) {
          arr[i] = Math.round(i * step);
        }
      }
      
      const interpolationType = elements.curveSmoothingMethod.value;
      const smoothingPercent = parseFloat(elements.smoothingSlider.value) || 0;
      
      // Step 2: Apply per-channel linearization on top of base curve
      if (channelName && perChannelLinearization[channelName] && perChannelEnabled[channelName]) {
        arr = apply1DLUT(arr, perChannelLinearization[channelName].samples, perChannelLinearization[channelName].domainMin, perChannelLinearization[channelName].domainMax, endValue, interpolationType, smoothingPercent);
      }
      
      // Step 3: Apply global linearization on top of everything
      if (applyLinearization && linearizationData && linearizationApplied) {
        arr = apply1DLUT(arr, linearizationData, linearizationData.domainMin, linearizationData.domainMax, endValue, interpolationType, smoothingPercent);
      }
      
      return arr;
    }

    // Randomized starting ink limits for visual variety
    function getRandomInkLimit(inkName) {
      // Define realistic ranges for different ink types - all with 100% upper bound for maximum variation
      const inkRanges = {
        K: [30, 100],     // Black: 30-100%
        C: [35, 100],     // Cyan: 35-100%
        M: [30, 100],     // Magenta: 30-100%
        Y: [40, 100],     // Yellow: 40-100%
        LC: [20, 100],    // Light Cyan: 20-100%
        LM: [20, 100],    // Light Magenta: 20-100%
        LK: [25, 100],    // Light Black: 25-100%
        LLK: [15, 100],   // Light Light Black: 15-100%
        V: [25, 100],     // Violet: 25-100%
        MK: [20, 100]     // Matte Black: 20-100%
      };
      
      const range = inkRanges[inkName] || [25, 45]; // Default range if ink not found
      const min = range[0];
      const max = range[1];
      
      // Generate random percentage within range
      return Math.floor(Math.random() * (max - min + 1)) + min;
    }

    // Extract channel row creation
    function createChannelRow(name, printerKey) {
      // Set default values based on printer and channel
      let defaultPercent = 0; // Default to disabled
      let channelEnabled = false; // Default to disabled
      
      // Enable only specific channels with 100%
      if (printerKey === 'P800' && name === 'K') {
        defaultPercent = 100;
        channelEnabled = true;
      } else if (printerKey === 'P700P900' && name === 'MK') {
        defaultPercent = 100;
        channelEnabled = true;
      }
      
      const defaultEndValue = InputValidator.computeEndFromPercent(defaultPercent);
      
      const tr = document.createElement('tr');
      tr.className = "border-t border-gray-200";
      tr.innerHTML = `
        <td class="px-1 py-2 text-center">
          <input type="checkbox" class="channel-enable-checkbox w-4 h-4" title="Enable/disable channel" ${channelEnabled ? 'checked' : ''}>
        </td>
        <td class="px-1 py-2 font-medium">
          <span class="inline-flex items-center gap-2">
            <span class="inline-block w-3.5 h-3.5 rounded-sm border border-black/10" style="background-color: ${INK_COLORS[name] || '#000'}"></span>
            <span class="w-8">${name}</span>
            <span class="text-xs text-gray-500 invisible" data-disabled>(disabled)</span>
          </span>
        </td>
        <td class="px-1 py-2">
          <div class="inline-flex items-center gap-2">
            <input type="file" id="perChannel_${name}" accept=".cube,.txt" class="hidden per-channel-file">
            <button class="per-channel-btn px-2 py-1 text-xs bg-gray-100 hover:bg-gray-200 text-gray-600 rounded transition-colors font-bold" data-channel="${name}" data-tooltip="Load LUT.cube or LABdata.txt files">load file</button>
            <label class="slider-toggle" title="Enable/disable per-channel linearization">
              <input type="checkbox" class="per-channel-toggle" data-channel="${name}" disabled>
              <span class="slider"></span>
            </label>
          </div>
        </td>
        <td class="px-1 py-2">
          <input type="number" step="1" min="0" max="100" value="${defaultPercent}" class="percent-input w-20 rounded-lg border border-gray-300 px-2 py-1 focus:outline-none focus:ring-2 focus:ring-blue-500">
        </td>
        <td class="px-1 py-2">
          <input type="number" step="1" min="0" max="64000" value="${defaultEndValue}" class="end-input w-20 rounded-lg border border-gray-300 px-2 py-1 focus:outline-none focus:ring-2 focus:ring-blue-500">
        </td>
      `;
      
      return tr;
    }

    function setupChannelRow(tr) {
      const percentInput = tr.querySelector('.percent-input');
      const endInput = tr.querySelector('.end-input');
      const disabledTag = tr.querySelector('[data-disabled]');
      const enableCheckbox = tr.querySelector('.channel-enable-checkbox');
      const perChannelBtn = tr.querySelector('.per-channel-btn');
      const perChannelFile = tr.querySelector('.per-channel-file');
      const perChannelToggle = tr.querySelector('.per-channel-toggle');
      const channelName = tr.dataset.channel;

      function refreshDisplay() {
        const endVal = InputValidator.clampEnd(endInput.value);
        endInput.value = String(endVal);
        
        const isUserDisabled = tr.hasAttribute('data-user-disabled');
        const isAtZero = endVal === 0;
        
        // Show disabled label if channel is at 0 (either user-disabled or set to 0%)
        disabledTag.classList.toggle('invisible', !isAtZero);
        
        // Update channel label opacity and row compactness
        const channelLabel = tr.querySelector('td:nth-child(2) span');
        const allCells = tr.querySelectorAll('td');
        const linearizationCell = tr.querySelector('td:nth-child(3)');
        const percentCell = tr.querySelector('td:nth-child(4)');
        const endCell = tr.querySelector('td:nth-child(5)');
        
        if (isAtZero) {
          channelLabel.style.opacity = '0.33';
          // Make row more compact when disabled
          allCells.forEach(cell => {
            cell.className = cell.className.replace('py-2', 'py-1');
          });
          // Hide linearization controls when disabled
          linearizationCell.style.visibility = 'hidden';
          // Reduce input sizes when disabled
          percentCell.style.opacity = '0.5';
          endCell.style.opacity = '0.5';
        } else {
          channelLabel.style.opacity = '1';
          // Restore normal padding when enabled
          allCells.forEach(cell => {
            cell.className = cell.className.replace('py-1', 'py-2');
          });
          // Show linearization controls when enabled
          linearizationCell.style.visibility = 'visible';
          // Restore input opacity when enabled
          percentCell.style.opacity = '1';
          endCell.style.opacity = '1';
        }
        
        // Update checkbox state based on channel status
        enableCheckbox.checked = !isAtZero;
      }
      
      // Store refreshDisplay function on the tr element for access from apply functions
      tr.refreshDisplayFn = refreshDisplay;

      // Channel enable/disable checkbox functionality
      const handleCheckboxChange = () => {
        const currentEndVal = InputValidator.clampEnd(endInput.value);
        const currentPercentVal = InputValidator.clampPercent(percentInput.value);
        
        if (enableCheckbox.checked) {
          // Enable: restore previous values or default to 33%
          const channelName = tr.dataset.channel;
          const previousValues = channelPreviousValues[channelName];
          
          if (previousValues && previousValues.percent > 0) {
            // Restore previous values
            percentInput.value = previousValues.percent.toString();
            endInput.value = previousValues.endValue.toString();
            showStatus(`Enabled ${channelName} (restored to ${previousValues.percent}%)`);
          } else {
            // Default to 33% if no previous value stored
            percentInput.value = '33';
            endInput.value = String(InputValidator.computeEndFromPercent(33));
            showStatus(`Enabled ${channelName} (set to default 33%)`);
          }
          
          tr.removeAttribute('data-user-disabled'); // Mark as not disabled by user
        } else {
          // Disable: store current values first, then set to 0
          const channelName = tr.dataset.channel;
          channelPreviousValues[channelName] = {
            percent: currentPercentVal,
            endValue: currentEndVal
          };
          
          percentInput.value = '0';
          endInput.value = '0';
          tr.setAttribute('data-user-disabled', 'true'); // Mark as disabled by user
          showStatus(`Disabled ${channelName} (saved ${currentPercentVal}% for restore)`);
        }
        
        refreshDisplay();
        debouncedPreviewUpdate();
      };
      
      enableCheckbox.addEventListener('change', handleCheckboxChange);

      // Use debounced updates to prevent excessive recalculations
      percentInput.addEventListener('input', () => {
        const p = InputValidator.validateInput(percentInput, InputValidator.clampPercent);
        const endVal = InputValidator.computeEndFromPercent(p);
        endInput.value = String(endVal);
        
        // If user manually changes from 0 to non-0, clear disabled state
        if (endVal > 0 && tr.hasAttribute('data-user-disabled')) {
          tr.removeAttribute('data-user-disabled');
        }
        
        // Update stored previous values with current manual change (if not disabled)
        if (endVal > 0 && !tr.hasAttribute('data-user-disabled')) {
          const channelName = tr.dataset.channel;
          channelPreviousValues[channelName] = {
            percent: p,
            endValue: endVal
          };
        }
        
        refreshDisplay();
        updateDisableAllButton(); // Update button state when individual channel values change
        debouncedPreviewUpdate();
      });

      endInput.addEventListener('input', () => {
        const e = InputValidator.validateInput(endInput, InputValidator.clampEnd);
        const p = InputValidator.computePercentFromEnd(e);
        percentInput.value = p.toFixed(1);
        
        // If user manually changes from 0 to non-0, clear disabled state
        if (e > 0 && tr.hasAttribute('data-user-disabled')) {
          tr.removeAttribute('data-user-disabled');
        }
        
        // Update stored previous values with current manual change (if not disabled)
        if (e > 0 && !tr.hasAttribute('data-user-disabled')) {
          const channelName = tr.dataset.channel;
          channelPreviousValues[channelName] = {
            percent: p,
            endValue: e
          };
        }
        
        refreshDisplay();
        updateDisableAllButton(); // Update button state when individual channel values change
        debouncedPreviewUpdate();
      });

      // Per-channel linearization button
      perChannelBtn.addEventListener('click', () => {
        perChannelFile.click();
      });
      
      // Per-channel file upload
      perChannelFile.addEventListener('change', async (e) => {
        const file = e.target.files[0];
        if (!file) return;
        
        try {
          // Per-channel supports both pre-made curves (.cube) and LAB data (.txt)
          const fileInput = await file.text();
          const parsed = await parseLinearizationFile(fileInput, file.name);
          perChannelLinearization[channelName] = parsed;
          perChannelEnabled[channelName] = true;
          perChannelFilenames[channelName] = file.name;
          
          // Enable and check toggle
          perChannelToggle.disabled = false;
          perChannelToggle.checked = true;
          
          // Update button tooltip with filename
          perChannelBtn.setAttribute('data-tooltip', `Loaded: ${file.name} (${parsed.samples.length} points)`);
          
          // Update interpolation controls since we now have linearization data
          updateInterpolationControls();
          
          // Show appropriate status message based on LUT type
          if (parsed.is3DLUT) {
            showStatus(`Loaded 3D LUT and extracted ${parsed.samples.length} neutral axis points for ${channelName} (${parsed.lutSize}¬≥ grid)`);
          } else {
            showStatus(`Loaded per-channel linearization for ${channelName}: ${parsed.samples.length} points`);
          }
          debouncedPreviewUpdate();
        } catch (error) {
          console.error('Per-channel linearization file error:', error);
          showStatus(`Error loading ${channelName} linearization: ${error.message}`);
          
          // Reset state on error
          delete perChannelLinearization[channelName];
          delete perChannelFilenames[channelName];
          perChannelEnabled[channelName] = false;
          perChannelToggle.disabled = true;
          perChannelToggle.checked = false;
          
          // Reset button tooltip
          perChannelBtn.setAttribute('data-tooltip', 'Load LUT.cube or LABdata.txt files');
          
          // Update interpolation controls since linearization may no longer be available
          updateInterpolationControls();
        }
      });
      
      // Per-channel toggle slider
      perChannelToggle.addEventListener('change', (e) => {
        if (perChannelLinearization[channelName]) {
          perChannelEnabled[channelName] = e.target.checked;
          if (perChannelEnabled[channelName]) {
            showStatus(`Enabled per-channel linearization for ${channelName}`);
          } else {
            showStatus(`Disabled per-channel linearization for ${channelName}`);
          }
          
          // Update filename to reflect current state
          updateFilename();
          
          debouncedPreviewUpdate();
        }
      });
      
      // Initialize per-channel state
      perChannelEnabled[channelName] = false;
      
      // Initial sync
      const initialP = InputValidator.clampPercent(percentInput.value);
      percentInput.value = initialP.toString();
      endInput.value = String(InputValidator.computeEndFromPercent(initialP));
      refreshDisplay();
    }

    // Optimized setPrinter with DocumentFragment
    function setPrinter(key) {
      try {
        // Clear loaded quad data when switching printers (unless we're switching due to a quad load)
        if (!loadedQuadData || loadedQuadData.switchingPrinter !== true) {
          clearLoadedQuadData();
        }
        
        const p = PRINTERS[key];
        const fragment = document.createDocumentFragment();
        
        p.channels.forEach(ch => {
          const tr = createChannelRow(ch, key);
          tr.dataset.channel = ch; // Add channel name to dataset
          fragment.appendChild(tr);
        });
        
        // Clear and update DOM in one operation
        elements.rows.innerHTML = "";
        elements.rows.appendChild(fragment);
        
        // Setup event listeners after DOM update
        Array.from(elements.rows.children).forEach(setupChannelRow);

        elements.channelInfo.innerHTML = "Channels: " + p.channels.map(ch => `<strong>${ch}</strong>`).join(", ");
        elements.printerDescription.innerHTML = "";
        
        // Use requestAnimationFrame for smooth UI update
        requestAnimationFrame(() => {
          updatePreview();
          updateInkChart();
          updateFilename(); // Update filename when printer changes
        });
        showStatus(`Switched to ${p.name}`);
      } catch (error) {
        console.error('Error setting printer:', error);
        showStatus("Error changing printer");
      }
    }

    function buildLimitsSummary() {
      const lines = ["# Limits summary:"];
      
      Array.from(elements.rows.children).forEach((tr) => {
        const name = tr.querySelector('td span span:nth-child(2)').textContent.trim();
        const e = InputValidator.clampEnd(tr.querySelector('.end-input').value);
        const p = InputValidator.computePercentFromEnd(e);
        
        if (e === 0) {
          lines.push("#   " + name + ": disabled");
        } else {
          const isWhole = Math.abs(p - Math.round(p)) < 1e-9;
          const percentFormatted = isWhole ? String(Math.round(p)) : p.toFixed(1);
          lines.push("#   " + name + ": = " + percentFormatted + "%");
        }
      });
      
      return lines;
    }

    function buildFile() {
      const p = PRINTERS[elements.printerSelect.value];
      const lines = [
        "## QuadToneRIP " + p.channels.join(","),
        "# Printer: " + p.name,
        `# quadGEN ${APP_VERSION} by David Marsh`
      ];
      
      // Add user notes if provided
      const userNotes = elements.userNotes.value.trim();
      if (userNotes) {
        lines.push("#");
        // Split notes by lines and add # prefix to each line
        userNotes.split('\n').forEach(line => {
          lines.push("# " + line.trim());
        });
      }
      
      // Add linearization information
      const hasLinearization = (linearizationData && linearizationApplied) || Object.keys(perChannelLinearization).length > 0;
      if (hasLinearization) {
        lines.push("#");
        lines.push("# Linearization Applied:");
        
        // Global linearization
        if (linearizationData && linearizationApplied) {
          const globalFilename = linearizationData.filename || "unknown file";
          lines.push(`# - Global: ${globalFilename} (${linearizationData.samples.length} points, affects all channels)`);
        }
        
        // Per-channel linearization
        const perChannelList = [];
        Object.keys(perChannelLinearization).forEach(channelName => {
          if (perChannelEnabled[channelName]) {
            const filename = perChannelFilenames[channelName] || "unknown file";
            const points = perChannelLinearization[channelName].samples.length;
            perChannelList.push(`${channelName}: ${filename} (${points} points)`);
          }
        });
        
        if (perChannelList.length > 0) {
          lines.push("# - Per-channel:");
          perChannelList.forEach(item => {
            lines.push(`#   ${item}`);
          });
        }
        
        // Interpolation method
        const method = elements.curveSmoothingMethod.value;
        const methodNames = {
          'cubic': 'Cubic Spline',
          'pchip': 'PCHIP (monotonic)',
          'linear': 'Linear (none)'
        };
        lines.push(`# - Interpolation: ${methodNames[method]}`);
        
        // Cubic splines now use pure interpolation (no intensity control)
      }
      
      lines.push(...buildLimitsSummary());

      // Build channel blocks efficiently
      p.channels.forEach((ch, idx) => {
        const row = elements.rows.children[idx];
        const e = InputValidator.clampEnd(row.querySelector('.end-input').value);
        const arr = make256(e, ch, true); // Apply linearization if enabled
        lines.push("# " + ch + " curve");
        lines.push(...arr.map(String));
      });

      return lines.join("\n") + "\n";
    }

    // Apply-to-all with improved performance and error handling
    elements.btnApplyPercent.addEventListener('click', () => {
      try {
        const val = InputValidator.clampPercent(elements.applyPercent.value);
        const endVal = InputValidator.computeEndFromPercent(val);
        
        Array.from(elements.rows.children).forEach(tr => {
          // Skip channels that are disabled (check both checkbox state and user-disabled attribute)
          const enableCheckbox = tr.querySelector('.channel-enable-checkbox');
          if (tr.hasAttribute('data-user-disabled') || (enableCheckbox && !enableCheckbox.checked)) {
            return;
          }
          
          const percentInput = tr.querySelector('.percent-input');
          const endInput = tr.querySelector('.end-input');
          percentInput.value = val.toString();
          endInput.value = String(endVal);
          
          // Trigger proper display update using the row's refreshDisplay function
          // We need to manually call refreshDisplay for each row
          const refreshDisplay = tr.refreshDisplayFn;
          if (refreshDisplay) {
            refreshDisplay();
          }
        });
        
        updatePreview();
        updateDisableAllButton(); // Update button state after applying values
        showStatus(`Applied ${val}% to all channels`);
      } catch (error) {
        console.error('Error applying percentage:', error);
        showStatus("Error applying percentage");
      }
    });

    elements.btnApplyEnd.addEventListener('click', () => {
      try {
        const val = InputValidator.clampEnd(elements.applyEnd.value);
        const percentVal = InputValidator.computePercentFromEnd(val);
        
        Array.from(elements.rows.children).forEach(tr => {
          // Skip channels that are disabled (check both checkbox state and user-disabled attribute)
          const enableCheckbox = tr.querySelector('.channel-enable-checkbox');
          if (tr.hasAttribute('data-user-disabled') || (enableCheckbox && !enableCheckbox.checked)) {
            return;
          }
          
          const percentInput = tr.querySelector('.percent-input');
          const endInput = tr.querySelector('.end-input');
          endInput.value = String(val);
          percentInput.value = percentVal.toFixed(1);
          
          // Trigger proper display update using the row's refreshDisplay function
          const refreshDisplay = tr.refreshDisplayFn;
          if (refreshDisplay) {
            refreshDisplay();
          }
        });
        
        updatePreview();
        updateDisableAllButton(); // Update button state after applying values
        showStatus(`Applied ${val} end value to all channels`);
      } catch (error) {
        console.error('Error applying end value:', error);
        showStatus("Error applying end value");
      }
    });

    // Download with enhanced error handling
    elements.downloadBtn.addEventListener('click', () => {
      try {
        const text = buildFile();
        const p = PRINTERS[elements.printerSelect.value];
        
        // Get custom filename or use default
        let filename;
        const customName = elements.filenameInput.value.trim();
        if (customName) {
          // Remove .quad extension if user added it, then sanitize
          const cleanName = customName.replace(/\.quad$/, '');
          const sanitizedName = sanitizeFilename(cleanName);
          
          // If sanitization removed everything, fall back to default
          if (!sanitizedName) {
            filename = p.name.replace(/\s+/g, '') + "_linear.quad";
            showStatus("Invalid filename, using default");
          } else {
            filename = sanitizedName + '.quad';
            
            // Show warning if filename was changed
            if (sanitizedName !== cleanName) {
              showStatus(`Filename sanitized: ${filename}`);
            }
          }
        } else {
          // Use default naming
          filename = p.name.replace(/\s+/g, '') + "_linear.quad";
        }
        
        const blob = new Blob([text], { type: "text/plain;charset=utf-8" });
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = filename;
        a.style.display = 'none';
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(url);
        
        showStatus(`Downloaded ${filename}`);
      } catch (error) {
        console.error('Download error:', error);
        showStatus("Error downloading file");
      }
    });

    // Keyboard shortcuts
    document.addEventListener('keydown', (e) => {
      if (e.ctrlKey || e.metaKey) {
        switch (e.key) {
          case 's':
            e.preventDefault();
            elements.downloadBtn.click();
            break;
          case 'r':
            e.preventDefault();
            updatePreview();
            break;
        }
      }
    });

    // Sample data loading functions
    function loadSampleData(type) {
      try {
        let correctionData;
        let filename;
        
        if (type === 'colorMuse') {
          correctionData = parseColorMuseData(SAMPLE_DATA.colorMuse, 'Color-Muse-Sample.txt');
          filename = 'LAB Sample Data';
        } else if (type === 'cube') {
          correctionData = parseCube1D(SAMPLE_DATA.gammaCube);
          filename = 'LUT Sample Data';
        } else {
          throw new Error('Invalid sample data type');
        }
        
        // Apply the correction as global linearization
        correctionData.filename = filename;
        linearizationData = correctionData;
        linearizationApplied = true;
        
        // Update UI to show applied correction
        elements.globalLinearizationBtn.setAttribute('data-tooltip', `Loaded: ${filename}`);
        elements.globalLinearizationToggle.disabled = false;
        elements.globalLinearizationToggle.checked = true;
        
        // Show file info
        elements.globalLinearizationInfo.classList.remove('hidden');
        elements.globalLinearizationFilename.textContent = filename;
        elements.globalLinearizationDetails.textContent = ` (${correctionData.format || 'Sample Data'})`;
        
        // Update interpolation controls
        updateInterpolationControls();
        updatePreview();
        
        // Update filename to reflect current state
        updateFilename();
        
        showStatus(`Loaded sample data: ${filename}`);
        
      } catch (error) {
        console.error('Error loading sample data:', error);
        showStatus(`Error loading sample data: ${error.message}`);
      }
    }


    // Initialize
    elements.printerSelect.addEventListener('change', (e) => setPrinter(e.target.value));
    
    // Add real-time filename validation
    elements.filenameInput.addEventListener('input', (e) => {
      const input = e.target;
      const value = input.value.trim();
      
      // Mark as user-edited if they've typed something different from auto-generated
      if (value !== generateFilename()) {
        input.dataset.userEdited = 'true';
      } else {
        delete input.dataset.userEdited;
      }
      
      if (value) {
        const cleanName = value.replace(/\.quad$/, '');
        const sanitized = sanitizeFilename(cleanName);
        const hasInvalidChars = sanitized !== cleanName;
        
        // Visual feedback for invalid characters
        input.classList.toggle('border-yellow-300', hasInvalidChars);
        input.classList.toggle('bg-yellow-50', hasInvalidChars);
        input.classList.toggle('border-gray-300', !hasInvalidChars);
        input.classList.toggle('bg-white', !hasInvalidChars);
        
        if (hasInvalidChars) {
          input.title = `Will be saved as: ${sanitized}.quad`;
        } else {
          input.title = '';
        }
      } else {
        input.classList.remove('border-yellow-300', 'bg-yellow-50');
        input.classList.add('border-gray-300', 'bg-white');
        input.title = '';
      }
    });

    // Linearization event listeners
    
    // Global linearization button click
    elements.globalLinearizationBtn.addEventListener('click', () => {
      elements.linearizationFile.click();
    });

    elements.linearizationFile.addEventListener('change', async (e) => {
      const file = e.target.files[0];
      if (!file) return;
      
      try {
        // Read file content as text
        const extension = file.name.toLowerCase().split('.').pop();
        const fileInput = await file.text();
        
        const parsed = await parseLinearizationFile(fileInput, file.name);
        parsed.filename = file.name; // Store filename for documentation
        linearizationData = parsed;
        linearizationApplied = true; // Auto-apply when file is loaded
        
        // Update button tooltip and enable toggle
        elements.globalLinearizationBtn.setAttribute('data-tooltip', `Loaded: ${file.name} (${parsed.samples.length} points)`);
        elements.globalLinearizationToggle.disabled = false;
        elements.globalLinearizationToggle.checked = true;
        
        // Show file info below Data Source label
        elements.globalLinearizationFilename.textContent = file.name;
        const formatInfo = parsed.format ? ` (${parsed.format})` : '';
        elements.globalLinearizationDetails.textContent = ` - ${parsed.samples.length} points${formatInfo}`;
        elements.globalLinearizationInfo.classList.remove('hidden');
        
        // Update interpolation controls
        updateInterpolationControls();
        
        // Show appropriate status message based on LUT type
        if (parsed.is3DLUT) {
          showStatus(`Loaded 3D LUT and extracted ${parsed.samples.length} neutral axis points from ${file.name} (${parsed.lutSize}¬≥ grid)`);
        } else {
          showStatus(`Loaded and applied ${parsed.samples.length} data points from ${file.name}`);
        }
        debouncedPreviewUpdate(); // Update preview to show the applied linearization
      } catch (error) {
        console.error('Cube file parsing error:', error);
        showStatus(`Error loading file: ${error.message}`);
        linearizationData = null;
        linearizationApplied = false;
        
        // Update filename to reflect no corrections
        updateFilename();
        
        // Reset button tooltip and disable toggle
        elements.globalLinearizationBtn.setAttribute('data-tooltip', 'Load LUT.cube or LABdata.txt files');
        elements.globalLinearizationToggle.disabled = true;
        elements.globalLinearizationToggle.checked = false;
        
        // Hide file info
        elements.globalLinearizationInfo.classList.add('hidden');
        
        // Update interpolation controls
        updateInterpolationControls();
      }
    });

    // Global linearization toggle
    elements.globalLinearizationToggle.addEventListener('change', (e) => {
      if (linearizationData) {
        linearizationApplied = e.target.checked;
        if (linearizationApplied) {
          showStatus('Global linearization enabled');
        } else {
          showStatus('Global linearization disabled');
        }
        
        // Update interpolation controls
        updateInterpolationControls();
        
        // Update filename to reflect current state
        updateFilename();
        
        debouncedPreviewUpdate();
      }
    });

    // Curve smoothing method selection
    elements.curveSmoothingMethod.addEventListener('change', (e) => {
      const method = e.target.value;
      
      // Update interpolation controls (including intensity slider visibility and description)
      updateInterpolationControls();
      
      if (hasAnyLinearization()) {
        const methodNames = {
          'cubic': 'Cubic Spline',
          'catmull': 'Catmull-Rom',
          'pchip': 'PCHIP (monotonic)',
          'linear': 'Linear (none)'
        };
        showStatus(`Curve method: ${methodNames[method]}`);
        debouncedPreviewUpdate(); // Update preview with new smoothing setting
      }
    });
    
    // Catmull-Rom tension slider
    elements.catmullTension.addEventListener('input', (e) => {
      if (hasAnyLinearization() && elements.curveSmoothingMethod.value === 'catmull') {
        const tension = Math.round(e.target.value);
        showStatus(`Catmull-Rom tension: ${tension}%`);
        debouncedPreviewUpdate(); // Update preview with new tension setting
      }
    });
    
    // Smoothing slider functionality
    elements.smoothingSlider.addEventListener('input', (e) => {
      if (hasAnyLinearization()) {
        const smoothingPercent = Math.round(e.target.value);
        elements.smoothingValue.textContent = `${smoothingPercent}%`;
        
        // Update warning visibility
        const showWarning = smoothingPercent > 0;
        elements.smoothingWarning.classList.toggle('hidden', !showWarning);
        
        // Update status and preview
        if (smoothingPercent > 0) {
          showStatus(`Data point smoothing: ${smoothingPercent}%`);
        } else {
          showStatus(`Data point smoothing: off`);
        }
        debouncedPreviewUpdate(); // Update preview with new smoothing setting
      }
    });
    
    // Simplification method change
    elements.simplificationMethod.addEventListener('change', (e) => {
      if (hasAnyLinearization()) {
        const method = e.target.value;
        const methodName = method === 'smoothing-splines' ? 'Smoothing Splines' : 'Uniform Sampling';
        showStatus(`Simplification method: ${methodName}`);
        debouncedPreviewUpdate(); // Update preview with new method
      }
    });
    
    
    // Notes toggle functionality
    elements.notesToggle.addEventListener('click', () => {
      const isHidden = elements.notesContent.classList.contains('hidden');
      
      if (isHidden) {
        // Expand
        elements.notesContent.classList.remove('hidden');
        elements.notesChevron.style.transform = 'rotate(180deg)';
      } else {
        // Collapse
        elements.notesContent.classList.add('hidden');
        elements.notesChevron.style.transform = 'rotate(0deg)';
      }
    });
    
    // Sample data button event listeners
    elements.loadSampleColorMuse.addEventListener('click', () => {
      loadSampleData('colorMuse');
    });
    
    elements.loadSampleCube.addEventListener('click', () => {
      loadSampleData('cube');
    });
    
    // Download sample data functionality
    function downloadFile(content, filename, mimeType) {
      const blob = new Blob([content], { type: mimeType });
      const url = window.URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = filename;
      document.body.appendChild(a);
      a.click();
      window.URL.revokeObjectURL(url);
      document.body.removeChild(a);
    }
    
    // Download sample data event listeners
    document.getElementById('downloadSampleColorMuse').addEventListener('click', (e) => {
      e.preventDefault();
      downloadFile(SAMPLE_DATA.colorMuse, 'LABdata_sample.txt', 'text/plain');
    });
    
    document.getElementById('downloadSampleCube').addEventListener('click', (e) => {
      e.preventDefault();
      downloadFile(SAMPLE_DATA.gammaCube, 'LUT_sample.cube', 'text/plain');
    });
    
    // Function to check if all channels are disabled
    function areAllChannelsDisabled() {
      const rows = Array.from(elements.rows.children);
      if (rows.length === 0) return false;
      
      return rows.every(tr => {
        const endInput = tr.querySelector('.end-input');
        return parseInt(endInput.value) === 0;
      });
    }
    
    // Function to update the disable/enable all button state
    function updateDisableAllButton() {
      const allDisabled = areAllChannelsDisabled();
      const button = elements.disableAllBtn;
      
      if (allDisabled) {
        button.textContent = 'Enable All';
        button.className = 'px-2 py-1 text-xs bg-green-100 text-green-700 hover:bg-green-200 rounded transition-colors font-bold w-24';
        button.title = 'Enable all channels (restore previous values)';
      } else {
        button.textContent = 'Disable All';
        button.className = 'px-2 py-1 text-xs bg-red-100 text-red-700 hover:bg-red-200 rounded transition-colors font-bold w-24';
        button.title = 'Disable all channels (set all to 0)';
      }
    }
    
    // Disable/Enable all channels functionality
    elements.disableAllBtn.addEventListener('click', () => {
      try {
        const allDisabled = areAllChannelsDisabled();
        let actionCount = 0;
        
        if (allDisabled) {
          // Enable all channels - restore previous values or set to defaults
          Array.from(elements.rows.children).forEach(tr => {
            const percentInput = tr.querySelector('.percent-input');
            const endInput = tr.querySelector('.end-input');
            const channelName = tr.dataset.channel;
            
            // Restore previous values if available, otherwise use defaults
            const previous = channelPreviousValues[channelName];
            let restorePercent = 33; // Default value
            let restoreEndValue = InputValidator.computeEndFromPercent(33);
            
            if (previous) {
              restorePercent = previous.percent;
              restoreEndValue = previous.endValue;
            }
            
            percentInput.value = restorePercent.toString();
            endInput.value = restoreEndValue.toString();
            tr.removeAttribute('data-user-disabled');
            
            // Use proper state management
            const refreshDisplay = tr.refreshDisplayFn;
            if (refreshDisplay) {
              refreshDisplay();
            }
            
            actionCount++;
          });
          
          showStatus(`Enabled all ${actionCount} channels`);
        } else {
          // Disable all channels
          Array.from(elements.rows.children).forEach(tr => {
            const percentInput = tr.querySelector('.percent-input');
            const endInput = tr.querySelector('.end-input');
            const channelName = tr.dataset.channel;
            
            // Store current values before disabling (if not already 0)
            const currentEndVal = InputValidator.clampEnd(endInput.value);
            const currentPercentVal = InputValidator.clampPercent(percentInput.value);
            
            if (currentEndVal > 0) {
              channelPreviousValues[channelName] = {
                percent: currentPercentVal,
                endValue: currentEndVal
              };
            }
            
            // Set to 0 and mark as user-disabled
            percentInput.value = '0';
            endInput.value = '0';
            tr.setAttribute('data-user-disabled', 'true');
            
            // Use proper state management
            const refreshDisplay = tr.refreshDisplayFn;
            if (refreshDisplay) {
              refreshDisplay();
            }
            
            actionCount++;
          });
          
          showStatus(`Disabled all ${actionCount} channels`);
        }
        
        updatePreview();
        updateDisableAllButton(); // Update button state after action
      } catch (error) {
        console.error('Error toggling all channels:', error);
        showStatus("Error toggling channels");
      }
    });
    
    // Load .quad file functionality
    function parseQuadFile(content) {
      const lines = content.split('\n').map(line => line.trim());
      
      // Look for the QuadToneRIP header line to extract channel names
      let channels = [];
      let dataStartIndex = -1;
      
      for (let i = 0; i < lines.length; i++) {
        const line = lines[i].trim();
        
        // Look for QuadToneRIP header: ## QuadToneRIP K,C,M,Y,LC,LM,LK,LLK
        if (line.startsWith('## QuadToneRIP ')) {
          const channelPart = line.substring('## QuadToneRIP '.length);
          channels = channelPart.split(',').map(ch => ch.trim());
          continue;
        }
        
        // Find where numeric data starts (first line that starts with a digit)
        if (dataStartIndex === -1 && line && line.match(/^\d/)) {
          dataStartIndex = i;
          break;
        }
      }
      
      if (channels.length === 0) {
        throw new Error('Could not find QuadToneRIP header with channel names in .quad file');
      }
      
      if (dataStartIndex === -1) {
        throw new Error('Could not find numeric data in .quad file');
      }
      
      // Parse the actual numeric data portion
      // Skip to where numeric data starts and collect all numeric lines
      const numericLines = [];
      let invalidDataLines = [];
      
      for (let i = dataStartIndex; i < lines.length; i++) {
        const line = lines[i].trim();
        if (line) {
          if (/^\d+$/.test(line)) {
            const value = parseInt(line, 10);
            
            // Validate reasonable value range for QuadToneRIP (0-65535)
            if (value < 0 || value > 65535) {
              throw new Error(`Invalid data value ${value} at line ${i + 1}. QuadToneRIP values must be 0-65535.`);
            }
            
            numericLines.push(value);
          } else if (!line.startsWith('#')) {
            // Track non-numeric, non-comment lines as potentially problematic
            invalidDataLines.push(`Line ${i + 1}: "${line}"`);
            if (invalidDataLines.length > 10) break; // Don't flood with errors
          }
        }
      }
      
      // Warn about mixed content if found
      if (invalidDataLines.length > 0) {
        const sampleLines = invalidDataLines.slice(0, 3).join(', ');
        console.warn(`Found ${invalidDataLines.length} non-numeric lines in data section: ${sampleLines}`);
      }
      
      // Each channel should have exactly 256 data points
      const expectedDataPoints = channels.length * 256;
      if (numericLines.length < expectedDataPoints) {
        throw new Error(`Insufficient data: found ${numericLines.length} values, expected ${expectedDataPoints} (${channels.length} channels √ó 256 points each)`);
      }
      
      // Extract all 256 data points for each channel
      const channelCurves = {};
      const values = []; // Final values for UI display
      
      for (let channelIdx = 0; channelIdx < channels.length; channelIdx++) {
        const channelName = channels[channelIdx];
        const channelStartIdx = channelIdx * 256;
        const channelEndIdx = channelStartIdx + 255; // 0-indexed, so 255 is the 256th value
        
        if (channelEndIdx >= numericLines.length) {
          throw new Error(`Not enough data for channel ${channelName}: need point ${channelEndIdx + 1}, have ${numericLines.length}`);
        }
        
        // Extract all 256 points for this channel
        const curveData = numericLines.slice(channelStartIdx, channelStartIdx + 256);
        channelCurves[channelName] = curveData;
        
        // Store the final value for UI display (percentage calculation)
        values.push(curveData[255]);
      }
      
      return { channels, values, curves: channelCurves };
    }
    
    function findMatchingPrinter(channels) {
      for (const [printerId, config] of Object.entries(PRINTERS)) {
        if (config.channels.length === channels.length && 
            config.channels.every((ch, i) => ch === channels[i])) {
          return printerId;
        }
      }
      return null;
    }
    
    // Load .quad file button click handler
    elements.loadQuadBtn.addEventListener('click', () => {
      elements.quadFile.click();
    });
    
    // Load .quad file change handler
    elements.quadFile.addEventListener('change', async (e) => {
      const file = e.target.files[0];
      if (!file) return;
      
      try {
        // Check file type
        if (!file.name.toLowerCase().endsWith('.quad')) {
          throw new Error(`Unsupported file type. Expected .quad file, got: ${file.name}`);
        }
        
        // Check file size (reasonable limits)
        if (file.size > 10 * 1024 * 1024) { // 10MB limit
          throw new Error(`File too large: ${(file.size / (1024*1024)).toFixed(1)}MB. Maximum supported size is 10MB.`);
        }
        
        if (file.size < 100) { // Minimum reasonable size
          throw new Error(`File too small: ${file.size} bytes. This doesn't appear to be a valid .quad file.`);
        }
        
        const content = await file.text();
        
        // Check for reasonable file structure
        if (!content.includes('QuadToneRIP')) {
          throw new Error('File does not appear to be a valid .quad file (missing QuadToneRIP header).');
        }
        
        // Check for reasonable data content
        const numericLines = content.split('\n').filter(line => line.trim() && /^\d+$/.test(line.trim()));
        if (numericLines.length < 256) {
          throw new Error(`File appears corrupted or incomplete. Found only ${numericLines.length} data points, expected at least 256.`);
        }
        
        const parsed = parseQuadFile(content);
        
        // Store the complete curve data for use in generation
        loadedQuadData = {
          filename: file.name,
          curves: parsed.curves,
          channels: parsed.channels
        };
        
        // Find matching printer
        const matchingPrinter = findMatchingPrinter(parsed.channels);
        if (!matchingPrinter) {
          const channelList = parsed.channels.join(', ');
          throw new Error(`No supported printer matches channels: ${channelList}. Supported printers: P800 (K,C,M,Y,LC,LM,LK,LLK), P700-P900 (K,C,M,Y,LC,LM,LK,LLK,V,MK)`);
        }
        
        // Switch to matching printer (mark that we're switching due to quad load)
        if (loadedQuadData) loadedQuadData.switchingPrinter = true;
        elements.printerSelect.value = matchingPrinter;
        setPrinter(matchingPrinter);
        if (loadedQuadData) delete loadedQuadData.switchingPrinter;
        
        // Wait a moment for the channel table to rebuild
        setTimeout(() => {
          // Set the channel values
          const rows = Array.from(elements.rows.children);
          parsed.values.forEach((value, index) => {
            if (index < rows.length) {
              const row = rows[index];
              const endInput = row.querySelector('.end-input');
              const percentInput = row.querySelector('.percent-input');
              
              if (endInput && percentInput) {
                endInput.value = value.toString();
                const percent = InputValidator.computePercentFromEnd(value);
                percentInput.value = percent.toString();
                
                // Refresh the row display
                const refreshFn = row.refreshDisplayFn;
                if (refreshFn) refreshFn();
              }
            }
          });
          
          updatePreview();
          
          // Show file info
          elements.quadFileInfo.textContent = `${file.name} - ${PRINTERS[matchingPrinter].name}`;
          elements.quadFileInfo.classList.remove('hidden');
          
          // Set the filename input to copy of the loaded file (remove .quad extension)
          const baseName = file.name.replace(/\.quad$/i, '');
          elements.filenameInput.value = `${baseName}_copy`;
          // Mark as user-edited so it won't be auto-generated over
          elements.filenameInput.dataset.userEdited = 'true';
          
          showStatus(`Loaded ${file.name} - switched to ${PRINTERS[matchingPrinter].name}`);
        }, 50);
        
      } catch (error) {
        console.error('Error loading .quad file:', error);
        showStatus(`Error loading .quad file: ${error.message}`);
      }
      
      // Clear the file input
      e.target.value = '';
    });
    
    // Manual L* entry functionality
    let lstarInputCount = 5;
    let lastLstarValues = []; // Store the last entered values
    
    function createLstarInput(index, value = '') {
      return `
        <div class="flex items-center gap-2">
          <span class="w-6 text-xs text-gray-500">${index + 1}.</span>
          <input type="number" class="lstar-input w-20 px-2 py-1 text-sm border border-gray-300 rounded focus:outline-none focus:ring-1 focus:ring-green-500 focus:border-green-500" 
                 placeholder="L*" 
                 min="0" max="100" step="0.1" value="${value}">
        </div>
      `;
    }
    
    function updateLstarInputs() {
      const container = elements.lstarInputs;
      container.innerHTML = '';
      
      for (let i = 0; i < lstarInputCount; i++) {
        const savedValue = lastLstarValues[i] || '';
        const inputHtml = createLstarInput(i, savedValue);
        container.insertAdjacentHTML('beforeend', inputHtml);
      }
      
      elements.lstarCountInput.value = lstarInputCount;
      elements.removeLstarInput.disabled = lstarInputCount <= 3;
      
      // Update validation
      validateLstarInputs();
    }
    
    function validateLstarInputs() {
      const inputs = elements.lstarInputs.querySelectorAll('.lstar-input');
      const values = [];
      let hasErrors = false;
      let errorMessage = '';
      
      inputs.forEach((input, index) => {
        const value = parseFloat(input.value);
        if (input.value.trim() && !isNaN(value)) {
          if (value < 0 || value > 100) {
            hasErrors = true;
            errorMessage = 'L* values must be between 0 and 100';
            input.style.borderColor = '#ef4444';
          } else {
            values.push({ index, value });
            input.style.borderColor = '#d1d5db';
          }
        } else if (input.value.trim()) {
          hasErrors = true;
          errorMessage = 'Invalid L* value';
          input.style.borderColor = '#ef4444';
        } else {
          input.style.borderColor = '#d1d5db';
        }
      });
      
      if (values.length < 3) {
        hasErrors = true;
        errorMessage = 'At least 3 L* values are required';
      }
      
      if (hasErrors) {
        elements.lstarValidation.textContent = errorMessage;
        elements.lstarValidation.classList.remove('hidden');
        elements.generateFromLstar.disabled = true;
      } else {
        elements.lstarValidation.classList.add('hidden');
        elements.generateFromLstar.disabled = false;
      }
      
      return { valid: !hasErrors, values };
    }
    
    function parseManualLstarData(lstarValues) {
      // Sort values by L* (highest to lowest for white to black)
      const sortedValues = lstarValues.sort((a, b) => b.value - a.value);
      
      // Create data points assuming even spacing from 0% to 100% input
      const dataPoints = sortedValues.map((item, index) => {
        const inputPercent = (index / (sortedValues.length - 1)) * 100;
        return { input: inputPercent, lab: item.value };
      });
      
      // Normalize L* values to full 0-1 density range
      const labValues = dataPoints.map(p => p.lab);
      const minLab = Math.min(...labValues);
      const maxLab = Math.max(...labValues);
      const labRange = maxLab - minLab;
      
      // NEW APPROACH: Flip the relationship like in parseColorMuseData
      // Convert L* to density-like values (invert since higher L* = lighter = lower density)
      const densityPoints = dataPoints.map(point => ({
        // Target density (from input): 0% should be 0 density, 100% should be 1 density
        targetDensity: point.input / 100,
        // What density we actually got (invert L* so high L* becomes low density)
        actualDensity: labRange > 0 ? 1.0 - ((point.lab - minLab) / labRange) : 0.5
      }));
      
      // Sort by target density
      densityPoints.sort((a, b) => a.targetDensity - b.targetDensity);
      
      console.log('Manual L* density mapping:', densityPoints.slice(0, 5)); // Debug first few points
      
      // Create correction curve: for each target density, find what input density produces it
      const samples = [];
      
      for (let i = 0; i < 256; i++) {
        const targetDensity = i / 255; // What density we want (0 = highlight, 1 = shadow)
        let correctedInput = targetDensity; // fallback to linear
        
        // Find what actual input produces this target density
        for (let j = 0; j < densityPoints.length - 1; j++) {
          const d1 = densityPoints[j];
          const d2 = densityPoints[j + 1];
          
          // Check if target falls between these actual density values
          const minActual = Math.min(d1.actualDensity, d2.actualDensity);
          const maxActual = Math.max(d1.actualDensity, d2.actualDensity);
          
          if (targetDensity >= minActual && targetDensity <= maxActual) {
            // Interpolate to find what target density produces this actual density
            const denom = d2.actualDensity - d1.actualDensity;
            if (Math.abs(denom) > 1e-10) {
              const t = (targetDensity - d1.actualDensity) / denom;
              correctedInput = d1.targetDensity + t * (d2.targetDensity - d1.targetDensity);
            }
            break;
          }
        }
        
        // Handle edge cases
        if (targetDensity < Math.min(...densityPoints.map(p => p.actualDensity))) {
          const minPoint = densityPoints.reduce((min, p) => p.actualDensity < min.actualDensity ? p : min);
          correctedInput = minPoint.targetDensity;
        } else if (targetDensity > Math.max(...densityPoints.map(p => p.actualDensity))) {
          const maxPoint = densityPoints.reduce((max, p) => p.actualDensity > max.actualDensity ? p : max);
          correctedInput = maxPoint.targetDensity;
        }
        
        samples.push(correctedInput);
      }
      
      // Dual transformation application: Coordinate system alignment with industry standard
      const flippedSamples = samples.map((sample, i) => {
        const inputPos = i / 255; // Current input position (0-1)
        const flippedInputPos = 1.0 - inputPos; // Horizontal flip
        const flippedInputIndex = Math.round(flippedInputPos * 255); // Convert back to index
        const clampedIndex = Math.max(0, Math.min(255, flippedInputIndex));
        const originalSample = samples[clampedIndex];
        const verticallyFlipped = 1.0 - originalSample; // Vertical flip
        return verticallyFlipped;
      });
      
      return {
        domainMin: 0.0,
        domainMax: 1.0,
        samples: flippedSamples,
        originalData: dataPoints,
        format: 'Manual L* Entry'
      };
    }
    
    // Modal event handlers
    elements.manualLstarBtn.addEventListener('click', () => {
      updateLstarInputs();
      elements.lstarModal.classList.remove('hidden');
    });
    
    elements.closeLstarModal.addEventListener('click', () => {
      elements.lstarModal.classList.add('hidden');
    });
    
    elements.cancelLstar.addEventListener('click', () => {
      elements.lstarModal.classList.add('hidden');
    });
    
    elements.lstarModal.addEventListener('click', (e) => {
      if (e.target === elements.lstarModal) {
        elements.lstarModal.classList.add('hidden');
      }
    });
    
    elements.addLstarInput.addEventListener('click', () => {
      if (lstarInputCount < 50) { // Increased maximum for more measurement points
        lstarInputCount++;
        updateLstarInputs();
      }
    });
    
    elements.removeLstarInput.addEventListener('click', () => {
      if (lstarInputCount > 3) {
        lstarInputCount--;
        updateLstarInputs();
      }
    });
    
    // Live validation as user types
    elements.lstarInputs.addEventListener('input', validateLstarInputs);
    
    // Handle direct input in the count field
    elements.lstarCountInput.addEventListener('input', (e) => {
      const value = parseInt(e.target.value);
      if (!isNaN(value) && value >= 3 && value <= 50) {
        lstarInputCount = value;
        updateLstarInputs();
      }
    });
    
    elements.generateFromLstar.addEventListener('click', () => {
      const validation = validateLstarInputs();
      if (!validation.valid) return;
      
      try {
        const correctionData = parseManualLstarData(validation.values);
        
        // Apply the correction as global linearization
        correctionData.filename = `Manual-L-${validation.values.length}pts`;
        linearizationData = correctionData;
        linearizationApplied = true;
        
        // Update UI to show applied correction
        elements.globalLinearizationBtn.setAttribute('data-tooltip', `Loaded: Manual L* (${validation.values.length} points)`);
        elements.globalLinearizationToggle.disabled = false;
        elements.globalLinearizationToggle.checked = true;
        
        // Show file info
        elements.globalLinearizationInfo.classList.remove('hidden');
        elements.globalLinearizationFilename.textContent = `Manual L* Entry`;
        elements.globalLinearizationDetails.textContent = ` (${validation.values.length} points)`;
        
        // Save the values for re-population
        const inputs = elements.lstarInputs.querySelectorAll('.lstar-input');
        lastLstarValues = Array.from(inputs).map(input => input.value);
        lstarInputCount = validation.values.length;
        
        // Update interpolation controls
        updateInterpolationControls();
        updatePreview();
        
        // Update filename to reflect current state
        updateFilename();
        
        elements.lstarModal.classList.add('hidden');
        
        showStatus(`Applied manual L* correction curve (${validation.values.length} points)`);
      } catch (error) {
        console.error('Error processing L* values:', error);
        showStatus(`Error processing L* values: ${error.message}`);
      }
    });
    
    // Function to populate changelog from main documentation
    function populateChangelog() {
      const changelogContent = document.getElementById('changelogContent');
      if (!changelogContent) return;
      
      // Since the changelog is in HTML comments, create it directly here
      // This ensures the info modal always shows the current changelog
      const changelogHtml = `
        <div>
          <p class="font-medium text-lg mb-3">Workflow Procedures:</p>
          <ol class="list-decimal list-inside space-y-1 ml-2 mb-4 text-sm">
            <li>Create a .quad file that specifies what ink or inks to use and their ink limit amounts</li>
            <li>Print a test target using that .quad file specifying initial ink limits</li>
            <li>Measure resulting print tonal result values with a Color Muse device (or other measurement device) OR generate a LUT (.cube) file using the EDN system at http://www.easydigitalnegatives.com/</li>
            <li>Import data into quadGEN (LAB data (.txt) file, manual L* entry, LUT (.cube), or try built-in sample data) and apply it to your initial ink limit setting</li>
            <li>Preview results in the curve graph and verify tonal shape</li>
            <li><em>Optional:</em> Adjust channel limits (enable/disable inks, apply uniform percentages if needed)</li>
            <li>Export the corrected .quad file and load it back into QuadToneRIP</li>
            <li>Reprint and validate with the corrected .quad file ‚Äî tonal reproduction should now closely match the target</li>
          </ol>
        </div>
        
        <div>
          <p class="font-medium text-lg mb-3">Version History:</p>
          
          <div class="mb-4">
            <p class="font-medium">v1.4.1 - Smoothing Algorithm Refinements:</p>
            <ul class="list-disc list-inside space-y-1 ml-2 mt-2 text-sm">
              <li><strong>Smoothing Splines:</strong> Added mathematical smoothing algorithm with automatic parameter selection</li>
              <li><strong>Visual Curve Comparison:</strong> Original curve overlay shows before/after smoothing effects on all channels</li>
              <li><strong>Streamlined Algorithm Selection:</strong> Focused on Uniform Sampling and Smoothing Splines for reliable results</li>
              <li><strong>Hidden Advanced Options:</strong> Removed Cubic Spline and Catmull-Rom interpolation from UI to reduce complexity</li>
              <li><strong>Improved Interpolation Defaults:</strong> PCHIP monotonic interpolation as primary method with Linear fallback</li>
            </ul>
          </div>
          
          <div class="mb-4">
            <p class="font-medium">v1.4 - Enhanced Curve Processing & UI:</p>
            <ul class="list-disc list-inside space-y-1 ml-2 mt-2 text-sm">
              <li><strong>Fixed Linear Interpolation:</strong> Now properly handles non-evenly spaced control points from LAB data</li>
              <li><strong>Enhanced LAB Data Processing:</strong> Smoothing works correctly, interpolation methods active immediately</li>
              <li><strong>Default Algorithm:</strong> Ramer-Douglas-Peucker now default for shape-preserving curve simplification</li>
              <li><strong>Built-in Sample Data:</strong> Download LAB measurement and Gamma 2.2 curve samples directly</li>
              <li><strong>Improved UI Layout:</strong> Compact two-column design with consistent styling throughout</li>
              <li><strong>Better Data Handling:</strong> Curve simplification works on original measurements, not interpolated curves</li>
            </ul>
          </div>
          
          <div class="mb-4">
            <p class="font-medium">v1.3 - Linearization Correction & Smoothing Features:</p>
            <ul class="list-disc list-inside space-y-1 ml-2 mt-2 text-sm">
              <li><strong>Algorithm Corrections:</strong> Color Muse and manual L* data entry linearization now match industry standards</li>
              <li><strong>Cube File Processing:</strong> Linearization corrected to use original samples directly</li>
              <li><strong>Data Transformation:</strong> Dual coordinate transformation applied to measurement data</li>
              <li><strong>Parser Improvements:</strong> Removed erroneous inverse mapping logic from .cube file parsing</li>
              <li><strong>Documentation:</strong> Added comprehensive explanations for different data treatments</li>
              <li><strong>Data Point Reduction:</strong> Multiple algorithms for reducing measurement points while preserving curve shape</li>
              <li><strong>Uniform Sampling:</strong> Even distribution point reduction maintaining start/end points</li>
              <li><strong>Ramer-Douglas-Peucker Algorithm:</strong> Shape-preserving curve simplification using perpendicular distance tolerance</li>
              <li><strong>Method Selection Interface:</strong> Real-time algorithm switching with immediate preview updates</li>
              <li><strong>Multi-Interpolation Support:</strong> Smoothed data works with Linear, Cubic, Catmull-Rom, and PCHIP interpolation methods</li>
              <li><strong>Coordinate System Integrity:</strong> Smoothing maintains proper coordinate transformations for all data types</li>
              <li><strong>Built-in Sample Data:</strong> Color Muse measurement sample and Gamma 2.2 curve sample for testing and learning</li>
            </ul>
          </div>
          
          <div class="mb-4">
            <p class="font-medium">v1.2 - Major Feature Release:</p>
            <ul class="list-disc list-inside space-y-1 ml-2 mt-2 text-sm">
              <li><strong>File Loading:</strong> Complete .quad file loading with curve preservation</li>
              <li><strong>Processing System:</strong> Layered processing system (base curves + linearization)</li>
              <li><strong>UI Enhancements:</strong> Enhanced interface with compact controls and better UX</li>
              <li><strong>Validation:</strong> Robust file validation and error handling</li>
              <li><strong>Printer Options:</strong> Streamlined printer options (P700-P900 merged)</li>
              <li><strong>Format Support:</strong> Removed ACV file support (limited open-source support)</li>
            </ul>
          </div>
          
          <div>
            <p class="font-medium">v1.1 - Previous Release:</p>
            <ul class="list-disc list-inside space-y-1 ml-2 mt-2 text-sm">
              <li><strong>Interpolation:</strong> Catmull-Rom spline interpolation with tension parameter</li>
              <li><strong>Channel Memory:</strong> Channel memory system for disabled channels</li>
              <li><strong>File Processing:</strong> Cube file inverse mapping corrections</li>
            </ul>
          </div>
        </div>
      `;
      
      changelogContent.innerHTML = changelogHtml;
    }
    
    // Info popup functionality
    elements.infoBtn.addEventListener('click', () => {
      populateChangelog();
      elements.infoPopup.classList.remove('hidden');
    });
    
    elements.closeInfoBtn.addEventListener('click', () => {
      elements.infoPopup.classList.add('hidden');
    });
    
    // Close popup when clicking outside
    elements.infoPopup.addEventListener('click', (e) => {
      if (e.target === elements.infoPopup) {
        elements.infoPopup.classList.add('hidden');
      }
    });
    
    // Close popup with Escape key
    document.addEventListener('keydown', (e) => {
      if (e.key === 'Escape' && !elements.infoPopup.classList.contains('hidden')) {
        elements.infoPopup.classList.add('hidden');
      }
    });
    
    // Update version displays using centralized variable
    function updateVersionDisplays() {
      document.title = `quadGEN ${APP_VERSION}`;
      document.getElementById('appVersion').textContent = APP_VERSION;
      document.getElementById('infoPopupTitle').textContent = `quadGEN ${APP_VERSION}`;
    }
    
    // Initial setup with error handling
    try {
      updateVersionDisplays(); // Set all version displays
      setPrinter('P700P900');
      updateDisableAllButton(); // Initialize button state
    } catch (error) {
      console.error('Initialization error:', error);
      showStatus("Initialization error. Please refresh the page.");
    }
  </script>

</body>
</html>